{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2a9205",
   "metadata": {},
   "source": [
    "# 基于MindSpore框架的SSD案例实现\n",
    "## 1 模型简介\n",
    "SSD模型于2016年在论文《SSD: Single Shot MultiBox Detector》中被提出。SSD是单阶段的目标检测算法，通过卷积神经网络进行特征提取，取不同的特征层进行检测输出，所以SSD是一种多尺度的检测方法。  \n",
    "在需要检测的特征层，直接使用一个3$\\times$3卷积，进行通道的变换。SSD采用了anchor的策略，预设不同长宽比例的anchor，每一个输出特征层基于anchor预测多个检测框（4或者6）。采用了多尺度检测方法，在浅层用于检测小目标，深层用于检测大目标。\n",
    "\n",
    "\n",
    "\n",
    "### 1.1 模型结构\n",
    "SSD采用VGG16作为基础模型，然后在VGG16的基础上新增了卷积层来获得更多的特征图以用于检测。SSD的网络结构如图1所示。上面是SSD模型，下面是Yolo模型，可以明显看到SSD利用了多尺度的特征图做检测。模型的输入图片大小是300$\\times$300（还可以是512$\\times$512，其与前者网络结构没有差别，只是最后新增一个卷积层）。  \n",
    "  \n",
    "![图片](./v2-a43295a3e146008b2131b160eec09cd4_r.jpg)\n",
    "\n",
    "图1 两种单阶段目标检测算法的比较  \n",
    "\n",
    "SSD先通过卷积不断进行特征提取，在需要检测物体的网络，直接通过一个3$\\times$3卷积得到输出，卷积的通道数由anchor数量和类别数量决定，具体为(anchor数量*(类别数量+4))。\n",
    "SSD对比了YOLO系列目标检测方法，不同的是SSD通过卷积得到最后的边界框，而YOLO对最后的输出采用全连接的形式得到一维向量，对向量进行拆解得到最终的检测框。\n",
    "### 1.2 模型特点\n",
    "  \n",
    "a)多尺度检测  \n",
    "在SSD的网络结构图中我们可以看到，SSD使用了多个特征层，特征层的尺寸分别是38$\\times$38，19$\\times$19，10$\\times$10，5$\\times$5，3$\\times$3，1$\\times$1，一共6种不同的特征图尺寸。大尺度特征图（较靠前的特征图）可以用来检测小物体，而小尺度特征图（较靠后的特征图）用来检测大物体。多尺度检测的方式，可以使得检测更加充分（SSD属于密集检测），更能检测出小目标。  \n",
    "\n",
    "b)采用卷积进行检测  \n",
    "与Yolo最后采用全连接层不同，SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为m$\\times$n$\\times$p的特征图，只需要采用3$\\times$3$\\times$p这样比较小的卷积核得到检测值。  \n",
    "\n",
    "c)预设anchor\n",
    "在yolov1中，直接由网络预测目标的尺寸，这种方式使得预测框的长宽比和尺寸没有限制，难以训练。在SSD中，采用预设边界框，我们习惯称它为anchor（在SSD论文中叫default bounding boxes），预测框的尺寸在anchor的指导下进行微调。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28267d5",
   "metadata": {},
   "source": [
    "## 2 案例实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095ccaa",
   "metadata": {},
   "source": [
    "### 2.1 环境准备与数据读取\n",
    "本案例基于MindSpore-GPU 1.8.1版本实现，在GPU上完成模型训练。  \n",
    "  \n",
    "案例所使用的数据为coco2017，下载链接，考虑到原始数据集过大，从中随机划分出100张图像作为训练集tiny_train_coco2017(下载链接)，50张图像作为测试集tiny_val_coco2017（下载链接），且将数据转换为了Mindrecord格式（下载链接）。  \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a40126",
   "metadata": {},
   "source": [
    "#### coco数据集转换成MindRecord格式\n",
    "MindSpore中可以把用于训练网络模型的数据集，转换为MindSpore特定的格式数据（MindSpore Record格式），从而更加方便地保存和加载数据。\n",
    "\n",
    "+ mindspore.mindrecord模块中定义了一个专门的类FileWriter可以将用户定义的原始数据写入MindRecord文件。\n",
    "\n",
    "+ 通过MindDataset接口，可以实现MindSpore Record文件的读取。\n",
    "\n",
    "+ 使用MindRecord的目标是归一化提供训练测试所用的数据集，并通过dataset模块的相关方法进行数据的读取，将这些高效的数据投入训练。\n",
    "\n",
    "\n",
    "\n",
    "![图片](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/tutorials/source_zh_cn/advanced/dataset/images/data_conversion_concept.png)\n",
    "\n",
    "MindRecord具备的特征如下：\n",
    "\n",
    "1. 实现多变的用户数据统一存储、访问，训练数据读取更加简便。\n",
    "2. 数据聚合存储，高效读取，且方便管理、移动。\n",
    "3. 高效的数据编解码操作，对用户透明、无感知。\n",
    "4. 可以灵活控制分区的大小，实现分布式训练。\n",
    "\n",
    "使用MindSpore Record数据格式可以减少磁盘IO、网络IO开销，从而获得更好的使用体验和性能提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c38e6db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ssd.mindrecord Mindrecord exists.\n",
      " ssd_eval.mindrecord Mindrecord exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "from src.config import get_config\n",
    "config = get_config()\n",
    "\n",
    "def create_coco_label(is_training):\n",
    "    \"\"\"Get image path and annotation from COCO.\"\"\"\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    coco_root = os.path.join(config.data_path, config.coco_root)\n",
    "    data_type = config.val_data_type\n",
    "    if is_training:\n",
    "        data_type = config.train_data_type\n",
    "\n",
    "    # Classes need to train or test.\n",
    "    train_cls = config.classes\n",
    "    train_cls_dict = {}\n",
    "    for i, cls in enumerate(train_cls):\n",
    "        train_cls_dict[cls] = i\n",
    "\n",
    "    anno_json = os.path.join(coco_root, config.instances_set.format(data_type))\n",
    "\n",
    "    coco = COCO(anno_json)\n",
    "    classs_dict = {}\n",
    "    cat_ids = coco.loadCats(coco.getCatIds())\n",
    "    for cat in cat_ids:\n",
    "        classs_dict[cat[\"id\"]] = cat[\"name\"]\n",
    "\n",
    "    image_ids = coco.getImgIds()\n",
    "    images = []\n",
    "    image_path_dict = {}\n",
    "    image_anno_dict = {}\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        image_info = coco.loadImgs(img_id)\n",
    "        file_name = image_info[0][\"file_name\"]\n",
    "        anno_ids = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "        anno = coco.loadAnns(anno_ids)\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        annos = []\n",
    "        iscrowd = False\n",
    "        for label in anno:\n",
    "            bbox = label[\"bbox\"]\n",
    "            class_name = classs_dict[label[\"category_id\"]]\n",
    "            iscrowd = iscrowd or label[\"iscrowd\"]\n",
    "            if class_name in train_cls:\n",
    "                x_min, x_max = bbox[0], bbox[0] + bbox[2]\n",
    "                y_min, y_max = bbox[1], bbox[1] + bbox[3]\n",
    "                annos.append(list(map(round, [y_min, x_min, y_max, x_max])) + [train_cls_dict[class_name]])\n",
    "\n",
    "        if not is_training and iscrowd:\n",
    "            continue\n",
    "        if len(annos) >= 1:\n",
    "            images.append(img_id)\n",
    "            image_path_dict[img_id] = image_path\n",
    "            image_anno_dict[img_id] = np.array(annos)\n",
    "\n",
    "    return images, image_path_dict, image_anno_dict\n",
    "\n",
    "def data_to_mindrecord_byte_image(dataset=\"coco\", is_training=True, prefix=\"ssd.mindrecord\", file_num=8):\n",
    "    \"\"\"Create MindRecord file.\"\"\"\n",
    "    mindrecord_path = os.path.join(config.data_path, config.mindrecord_dir, prefix)\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    images, image_path_dict, image_anno_dict = create_coco_label(is_training)\n",
    "    ssd_json = {\n",
    "        \"img_id\": {\"type\": \"int32\", \"shape\": [1]},\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 5]},\n",
    "    }\n",
    "    writer.add_schema(ssd_json, \"ssd_json\")\n",
    "\n",
    "    for img_id in images:\n",
    "        image_path = image_path_dict[img_id]\n",
    "        with open(image_path, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[img_id], dtype=np.int32)\n",
    "        img_id = np.array([img_id], dtype=np.int32)\n",
    "        row = {\"img_id\": img_id, \"image\": img, \"annotation\": annos}\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def create_mindrecord(dataset=\"coco\", prefix=\"ssd.mindrecord\", is_training=True):\n",
    "\n",
    "    mindrecord_dir = os.path.join(config.data_path, config.mindrecord_dir)\n",
    "    mindrecord_file = os.path.join(mindrecord_dir, prefix + \"0\")\n",
    "    os.makedirs(mindrecord_dir,exist_ok=True)\n",
    "    if not os.path.exists(mindrecord_file):\n",
    "        print(\"Create {} Mindrecord.\".format(prefix))\n",
    "        data_to_mindrecord_byte_image(\"coco\", is_training, prefix)\n",
    "        print(\"Create {} Mindrecord Done, at {}\".format(prefix,mindrecord_dir))\n",
    "    else:\n",
    "        print(\" {} Mindrecord exists.\".format(prefix))\n",
    "    return mindrecord_file\n",
    "\n",
    "#训练数据转换为mindrecord格式\n",
    "mindrecord_file = create_mindrecord(config.dataset, \"ssd.mindrecord\", True)\n",
    "#测试数据转换为mindrecord格式\n",
    "eval_mindrecord_file = create_mindrecord(config.dataset, \"ssd_eval.mindrecord\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb22c7",
   "metadata": {},
   "source": [
    "## 数据预处理  \n",
    "### 随机采样\n",
    "### 数据增强\n",
    "数据统一resize为300$\\times$300大小  \n",
    "SSD算法中采用了以下几种数据增强的方法：  \n",
    "随机裁剪：随机裁剪一个部分，每个采样部分的大小为原图的[0.3,1]，长宽比在1/2和2之间。如果真实标签框的中心位于采样部分内，则保留真实框与图片重叠的部分。  \n",
    "水平翻转：对采样后的小图片进行0.5概率的随机水平翻转 .  \n",
    "└─cocodataset  \n",
    "&nbsp;&nbsp;├─annotations\n",
    "    ├─instance_train2017.json\n",
    "    └─instance_val2017.json\n",
    "  ├─val2017\n",
    "  └─train2017 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ee15b",
   "metadata": {},
   "source": [
    "### 定义数据预处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a23487",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ml_collections'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28156/3264920647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjaccard_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssd_bboxes_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_rand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ms-redpanda/ssd_ms/src/box_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridAnchorGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ms-redpanda/ssd_ms/src/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mml_collections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ml_collections'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from src.box_utils import jaccard_numpy, ssd_bboxes_encode\n",
    "\n",
    "def _rand(a=0., b=1.):\n",
    "    \"\"\"Generate random.\"\"\"\n",
    "    return np.random.rand() * (b - a) + a\n",
    "\n",
    "def random_sample_crop(image, boxes):\n",
    "    \"\"\"Random Crop the image and boxes\"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    min_iou = np.random.choice([None, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "    if min_iou is None:\n",
    "        return image, boxes\n",
    "\n",
    "    # max trails (50)\n",
    "    for _ in range(50):\n",
    "        image_t = image\n",
    "        w = _rand(0.3, 1.0) * width\n",
    "        h = _rand(0.3, 1.0) * height\n",
    "        # aspect ratio constraint b/t .5 & 2\n",
    "        if h / w < 0.5 or h / w > 2:\n",
    "            continue\n",
    "\n",
    "        left = _rand() * (width - w)\n",
    "        top = _rand() * (height - h)\n",
    "        rect = np.array([int(top), int(left), int(top + h), int(left + w)])\n",
    "        overlap = jaccard_numpy(boxes, rect)\n",
    "\n",
    "        # dropout some boxes\n",
    "        drop_mask = overlap > 0\n",
    "        if not drop_mask.any():\n",
    "            continue\n",
    "\n",
    "        if overlap[drop_mask].min() < min_iou and overlap[drop_mask].max() > (min_iou + 0.2):\n",
    "            continue\n",
    "\n",
    "        image_t = image_t[rect[0]:rect[2], rect[1]:rect[3], :]\n",
    "        centers = (boxes[:, :2] + boxes[:, 2:4]) / 2.0\n",
    "        m1 = (rect[0] < centers[:, 0]) * (rect[1] < centers[:, 1])\n",
    "        m2 = (rect[2] > centers[:, 0]) * (rect[3] > centers[:, 1])\n",
    "\n",
    "        # mask in that both m1 and m2 are true\n",
    "        mask = m1 * m2 * drop_mask\n",
    "\n",
    "        # have any valid boxes? try again if not\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        # take only matching gt boxes\n",
    "        boxes_t = boxes[mask, :].copy()\n",
    "        boxes_t[:, :2] = np.maximum(boxes_t[:, :2], rect[:2])\n",
    "        boxes_t[:, :2] -= rect[:2]\n",
    "        boxes_t[:, 2:4] = np.minimum(boxes_t[:, 2:4], rect[2:4])\n",
    "        boxes_t[:, 2:4] -= rect[:2]\n",
    "\n",
    "        return image_t, boxes_t\n",
    "    return image, boxes\n",
    "\n",
    "\n",
    "def preprocess_fn(img_id, image, box, is_training):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "    cv2.setNumThreads(2)\n",
    "\n",
    "    def _infer_data(image, input_shape):\n",
    "        img_h, img_w, _ = image.shape\n",
    "        input_h, input_w = input_shape\n",
    "\n",
    "        image = cv2.resize(image, (input_w, input_h))\n",
    "\n",
    "        # When the channels of image is 1\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            image = np.concatenate([image, image, image], axis=-1)\n",
    "\n",
    "        return img_id, image, np.array((img_h, img_w), np.float32)\n",
    "\n",
    "    def _data_aug(image, box, is_training, image_size=(300, 300)):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        ih, iw, _ = image.shape\n",
    "        h, w = image_size\n",
    "        if not is_training:\n",
    "            return _infer_data(image, image_size)\n",
    "        # Random crop\n",
    "        box = box.astype(np.float32)\n",
    "        image, box = random_sample_crop(image, box)\n",
    "        ih, iw, _ = image.shape\n",
    "        # Resize image\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        # Flip image or not\n",
    "        flip = _rand() < .5\n",
    "        if flip:\n",
    "            image = cv2.flip(image, 1, dst=None)\n",
    "        # When the channels of image is 1\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            image = np.concatenate([image, image, image], axis=-1)\n",
    "        box[:, [0, 2]] = box[:, [0, 2]] / ih\n",
    "        box[:, [1, 3]] = box[:, [1, 3]] / iw\n",
    "        if flip:\n",
    "            box[:, [1, 3]] = 1 - box[:, [3, 1]]\n",
    "        box, label, num_match = ssd_bboxes_encode(box)\n",
    "        return image, box, label, num_match\n",
    "    return _data_aug(image, box, is_training, image_size=config.img_shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18d684",
   "metadata": {},
   "source": [
    "### 2.2 数据集创建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3695959",
   "metadata": {},
   "source": [
    "### 定义dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec706a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import mindspore.dataset as de\n",
    "\n",
    "def create_ssd_dataset(mindrecord_file, batch_size=32, device_num=1, rank=0,\n",
    "                       is_training=True, num_parallel_workers=6, use_multiprocessing=True):\n",
    "    \"\"\"Create SSD dataset with MindDataset.\"\"\"\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    if cores < num_parallel_workers:\n",
    "        print(\"The num_parallel_workers {} is set too large, now set it {}\".format(num_parallel_workers, cores))\n",
    "        num_parallel_workers = cores\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"img_id\", \"image\", \"annotation\"], num_shards=device_num,\n",
    "                        shard_id=rank, num_parallel_workers=num_parallel_workers, shuffle=is_training)\n",
    "    decode = de.vision.Decode()\n",
    "    ds = ds.map(operations=decode, input_columns=[\"image\"])\n",
    "    change_swap_op = de.vision.HWC2CHW()\n",
    "    # Computed from random subset of ImageNet training images\n",
    "    normalize_op = de.vision.Normalize(mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "                                       std=[0.229 * 255, 0.224 * 255, 0.225 * 255])\n",
    "    color_adjust_op = de.vision.RandomColorAdjust(brightness=0.4, contrast=0.4, saturation=0.4)\n",
    "    compose_map_func = (lambda img_id, image, annotation: preprocess_fn(img_id, image, annotation, is_training))\n",
    "    if is_training:\n",
    "        output_columns = [\"image\", \"box\", \"label\", \"num_match\"]\n",
    "        trans = [color_adjust_op, normalize_op, change_swap_op]\n",
    "    else:\n",
    "        output_columns = [\"img_id\", \"image\", \"image_shape\"]\n",
    "        trans = [normalize_op, change_swap_op]\n",
    "    ds = ds.map(operations=compose_map_func, input_columns=[\"img_id\", \"image\", \"annotation\"],\n",
    "                output_columns=output_columns, column_order=output_columns,\n",
    "                python_multiprocessing=use_multiprocessing,\n",
    "                num_parallel_workers=num_parallel_workers)\n",
    "    ds = ds.map(operations=trans, input_columns=[\"image\"], python_multiprocessing=use_multiprocessing,\n",
    "                num_parallel_workers=num_parallel_workers)\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f75e8f",
   "metadata": {},
   "source": [
    "## 4 模型构建\n",
    "本案例实现过程中采用VGG16做基础模型，并在之上进行了一些改善。首先VGG16是在ILSVRC CLS-LOC数据集预训练。输入图像经过预处理后大小固定为300×300，首先经过backbone，本案例中使用的是VGG16网络的前13个卷积层，然后分别将VGG16的全连接层fc6和fc7转换成3$\\times$3卷积层block6和1$\\times$1卷积层block7，进一步提取特征。  \n",
    "\n",
    "![图片](./441a293cb82c1ebecc4f67b0e03c2b05.png)  \n",
    "\n",
    "图2 基础的VGG结构  \n",
    "\n",
    "在block6中，使用了空洞数为6的空洞卷积，其padding也为6，这样做同样也是为了增加感受野的同时保持参数量与特征图尺寸的不变。 利用mindspore构造该基础网络时，只需要在官方VGG16的基础上进行一些修改即可。  \n",
    "在VGG 16的基础上，SSD进一步增加了4个深度卷积层，用于更高语义信息的提取。block8的通道数为512，而block9、block10与block11的通道数都为256。为了降低参数量，在此使用了1×1卷积先降低通道数为该层输出通道数的一半，再利用3×3卷积进行特征提取。  \n",
    "\n",
    "原文链接：https://blog.csdn.net/weixin_45564943/article/details/121793331  \n",
    "其中VGG16中的Conv4_3层将作为用于检测的第一个特征图。conv4_3层特征图大小是  ，但是该层比较靠前，其norm较大，所以在其后面增加了一个L2 Normalization层（参见ParseNet），以保证和后面的检测层差异不是很大，这个和Batch Normalization层不太一样，其仅仅是对每个像素点在channle维度做归一化，而Batch Normalization层是在[batch_size, width, height]三个维度上做归一化。    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc11d2",
   "metadata": {},
   "source": [
    "### 定义SSD网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "354a9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from src.vgg16 import vgg16\n",
    "import mindspore.ops as ops\n",
    "import ml_collections\n",
    "from src.config import get_config\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"nsures that all layers have a channel number that is divisible by 8.\"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def _conv2d(in_channel, out_channel, kernel_size=3, stride=1, pad_mod='same'):\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride,\n",
    "                     padding=0, pad_mode=pad_mod, has_bias=True)\n",
    "\n",
    "def _bn(channel):\n",
    "    return nn.BatchNorm2d(channel, eps=1e-3, momentum=0.97,\n",
    "                          gamma_init=1, beta_init=0, moving_mean_init=0, moving_var_init=1)\n",
    "def _last_conv2d(in_channel, out_channel, kernel_size=3, stride=1, pad_mod='same', pad=0):\n",
    "    in_channels = in_channel\n",
    "    out_channels = in_channel\n",
    "    depthwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad_mode='same',\n",
    "                               padding=pad, group=in_channels)\n",
    "    conv = _conv2d(in_channel, out_channel, kernel_size=1)\n",
    "    return nn.SequentialCell([depthwise_conv, _bn(in_channel), nn.ReLU6(), conv])\n",
    "\n",
    "class FlattenConcat(nn.Cell):\n",
    "    \"\"\"\n",
    "    Concatenate predictions into a single tensor.\n",
    "\n",
    "    Args:\n",
    "        config (dict): The default config of SSD.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, flatten predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(FlattenConcat, self).__init__()\n",
    "        self.num_ssd_boxes = config.num_ssd_boxes\n",
    "        self.concat = ops.Concat(axis=1)\n",
    "        self.transpose = ops.Transpose()\n",
    "    def construct(self, inputs):\n",
    "        output = ()\n",
    "        batch_size = ops.shape(inputs[0])[0]\n",
    "        for x in inputs:\n",
    "            x = self.transpose(x, (0, 2, 3, 1))\n",
    "            output += (ops.reshape(x, (batch_size, -1)),)\n",
    "        res = self.concat(output)\n",
    "        return ops.reshape(res, (batch_size, self.num_ssd_boxes, -1))\n",
    "\n",
    "\n",
    "class MultiBox(nn.Cell):\n",
    "    \"\"\"\n",
    "    Multibox conv layers. Each multibox layer contains class conf scores and localization predictions.\n",
    "\n",
    "    Args:\n",
    "        config (dict): The default config of SSD.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, localization predictions.\n",
    "        Tensor, class conf scores.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(MultiBox, self).__init__()\n",
    "        num_classes = 81\n",
    "        out_channels = config.extras_out_channels\n",
    "        num_default = config.num_default\n",
    "\n",
    "        loc_layers = []\n",
    "        cls_layers = []\n",
    "        for k, out_channel in enumerate(out_channels):\n",
    "            loc_layers += [_last_conv2d(out_channel, 4 * num_default[k],\n",
    "                                        kernel_size=3, stride=1, pad_mod='same', pad=0)]\n",
    "            cls_layers += [_last_conv2d(out_channel, num_classes * num_default[k],\n",
    "                                        kernel_size=3, stride=1, pad_mod='same', pad=0)]\n",
    "\n",
    "        self.multi_loc_layers = nn.layer.CellList(loc_layers)\n",
    "        self.multi_cls_layers = nn.layer.CellList(cls_layers)\n",
    "        self.flatten_concat = FlattenConcat(config)\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        loc_outputs = ()\n",
    "        cls_outputs = ()\n",
    "        for i in range(len(self.multi_loc_layers)):\n",
    "            loc_outputs += (self.multi_loc_layers[i](inputs[i]),)\n",
    "            cls_outputs += (self.multi_cls_layers[i](inputs[i]),)\n",
    "        return self.flatten_concat(loc_outputs), self.flatten_concat(cls_outputs)\n",
    "\n",
    "       \n",
    "class SSD300VGG16(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super(SSD300VGG16, self).__init__()\n",
    "\n",
    "        # VGG16 backbone: block1~5\n",
    "        self.backbone = vgg16()\n",
    "\n",
    "        # SSD blocks: block6~7\n",
    "        self.b6_1 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=6, dilation=6, pad_mode='pad')\n",
    "        self.b6_2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.b7_1 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=1)\n",
    "        self.b7_2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Extra Feature Layers: block8~11\n",
    "        self.b8_1 = nn.Conv2d(in_channels=1024, out_channels=256, kernel_size=1, padding=1, pad_mode='pad')\n",
    "        self.b8_2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, pad_mode='valid')\n",
    "\n",
    "        self.b9_1 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1, padding=1, pad_mode='pad')\n",
    "        self.b9_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, pad_mode='valid')\n",
    "\n",
    "        self.b10_1 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1)\n",
    "        self.b10_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, pad_mode='valid')\n",
    "\n",
    "        self.b11_1 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1)\n",
    "        self.b11_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, pad_mode='valid')\n",
    "\n",
    "        # boxes\n",
    "        self.multi_box = MultiBox(config)\n",
    "        if not self.training:\n",
    "            self.activation = ops.Sigmoid()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # VGG16 backbone: block1~5\n",
    "        block4, x = self.backbone(x)\n",
    "\n",
    "        # SSD blocks: block6~7\n",
    "        x = self.b6_1(x)  # 1024\n",
    "        x = self.b6_2(x)\n",
    "\n",
    "        x = self.b7_1(x)  # 1024\n",
    "        x = self.b7_2(x)\n",
    "        block7 = x\n",
    "\n",
    "        # Extra Feature Layers: block8~11\n",
    "        x = self.b8_1(x)  # 256\n",
    "        x = self.b8_2(x)  # 512\n",
    "        block8 = x\n",
    "\n",
    "        x = self.b9_1(x)  # 128\n",
    "        x = self.b9_2(x)  # 256\n",
    "        block9 = x\n",
    "\n",
    "        x = self.b10_1(x)  # 128\n",
    "        x = self.b10_2(x)  # 256\n",
    "        block10 = x\n",
    "\n",
    "        x = self.b11_1(x)  # 128\n",
    "        x = self.b11_2(x)  # 256\n",
    "        block11 = x\n",
    "\n",
    "        # boxes\n",
    "        multi_feature = (block4, block7, block8, block9, block10, block11)\n",
    "        pred_loc, pred_label = self.multi_box(multi_feature)\n",
    "        if not self.training:\n",
    "            pred_label = self.activation(pred_label)\n",
    "        pred_loc = ops.cast(pred_loc, ms.float32)\n",
    "        pred_label = ops.cast(pred_label, ms.float32)\n",
    "        return pred_loc, pred_label\n",
    "    \n",
    "    \n",
    "def ssd_vgg16(**kwargs):\n",
    "    return SSD300VGG16(**kwargs)   \n",
    "ssd = ssd_vgg16(config=config)\n",
    "# init_net_param(ssd)\n",
    "# print(ssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a19ba3",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "损失函数定义为位置误差（locatization loss， loc）与置信度误差（confidence loss, conf）的加权和：  \n",
    "其中  是先验框的正样本数量。这里  为一个指示参数，当  时表示第  个先验框与第  个ground truth匹配，并且ground truth的类别为  。  为类别置信度预测值。  为先验框的所对应边界框的位置预测值，而  是ground truth的位置参数。对于位置误差，其采用Smooth L1 loss，定义如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edacc6",
   "metadata": {},
   "source": [
    "### 定义LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72446fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "\n",
    "grad_scale = ops.MultitypeFuncGraph(\"grad_scale\")\n",
    "\n",
    "class SigmoidFocalClassificationLoss(nn.Cell):\n",
    "    \"\"\"\"\n",
    "    Sigmoid focal-loss for classification.\n",
    "\n",
    "    Args:\n",
    "        gamma (float): Hyper-parameter to balance the easy and hard examples. Default: 2.0\n",
    "        alpha (float): Hyper-parameter to balance the positive and negative example. Default: 0.25\n",
    "\n",
    "    Returns:\n",
    "        Tensor, the focal loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(SigmoidFocalClassificationLoss, self).__init__()\n",
    "        self.sigmiod_cross_entropy = ops.SigmoidCrossEntropyWithLogits()\n",
    "        self.sigmoid = ops.Sigmoid()\n",
    "        self.pow = ops.Pow()\n",
    "        self.onehot = ops.OneHot()\n",
    "        self.on_value = Tensor(1.0, ms.float32)\n",
    "        self.off_value = Tensor(0.0, ms.float32)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def construct(self, logits, label):\n",
    "        label = self.onehot(label, ops.shape(logits)[-1], self.on_value, self.off_value)\n",
    "        sigmiod_cross_entropy = self.sigmiod_cross_entropy(logits, label)\n",
    "        sigmoid = self.sigmoid(logits)\n",
    "        label = ops.cast(label, ms.float32)\n",
    "        p_t = label * sigmoid + (1 - label) * (1 - sigmoid)\n",
    "        modulating_factor = self.pow(1 - p_t, self.gamma)\n",
    "        alpha_weight_factor = label * self.alpha + (1 - label) * (1 - self.alpha)\n",
    "        focal_loss = modulating_factor * alpha_weight_factor * sigmiod_cross_entropy\n",
    "        return focal_loss\n",
    "\n",
    "class SSDWithLossCell(nn.Cell):\n",
    "    \"\"\"\"\n",
    "    Provide SSD training loss through network.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): The training network.\n",
    "        config (dict): SSD config.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, the loss of the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, network, config):\n",
    "        super(SSDWithLossCell, self).__init__()\n",
    "        self.network = network\n",
    "        self.less = ops.Less()\n",
    "        self.tile = ops.Tile()\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.expand_dims = ops.ExpandDims()\n",
    "        self.class_loss = SigmoidFocalClassificationLoss(config.gamma, config.alpha)\n",
    "        self.loc_loss = nn.SmoothL1Loss()\n",
    "\n",
    "    def construct(self, x, gt_loc, gt_label, num_matched_boxes):\n",
    "        pred_loc, pred_label = self.network(x)\n",
    "        mask = ops.cast(self.less(0, gt_label), ms.float32)\n",
    "        num_matched_boxes = self.reduce_sum(ops.cast(num_matched_boxes, ms.float32))\n",
    "\n",
    "        # Localization Loss\n",
    "        mask_loc = self.tile(self.expand_dims(mask, -1), (1, 1, 4))\n",
    "        smooth_l1 = self.loc_loss(pred_loc, gt_loc) * mask_loc\n",
    "        loss_loc = self.reduce_sum(self.reduce_sum(smooth_l1, -1), -1)\n",
    "\n",
    "        # Classification Loss\n",
    "        loss_cls = self.class_loss(pred_label, gt_label)\n",
    "        loss_cls = self.reduce_sum(loss_cls, (1, 2))\n",
    "\n",
    "        return self.reduce_sum((loss_cls + loss_loc) / num_matched_boxes)\n",
    "    \n",
    "    \n",
    "net = SSDWithLossCell(ssd, config)\n",
    "#print(net)\n",
    "#print('-----------------------')\n",
    "#print(ssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b2cc1",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590d1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "from mindspore import save_checkpoint\n",
    "from mindspore import log as logger\n",
    "from mindspore.train.callback import Callback\n",
    "import json\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from src.config import get_config\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "def apply_eval(eval_param_dict):\n",
    "    net = eval_param_dict[\"net\"]\n",
    "    net.set_train(False)\n",
    "    ds = eval_param_dict[\"dataset\"]\n",
    "    anno_json = eval_param_dict[\"anno_json\"]\n",
    "    coco_metrics = COCOMetrics(anno_json=anno_json,\n",
    "                               classes=config.classes,\n",
    "                               num_classes=config.num_classes,\n",
    "                               max_boxes=config.max_boxes,\n",
    "                               nms_threshold=config.nms_threshold,\n",
    "                               min_score=config.min_score)\n",
    "    for data in ds.create_dict_iterator(output_numpy=True, num_epochs=1):\n",
    "        img_id = data['img_id']\n",
    "        img_np = data['image']\n",
    "        image_shape = data['image_shape']\n",
    "\n",
    "        output = net(Tensor(img_np))\n",
    "\n",
    "        for batch_idx in range(img_np.shape[0]):\n",
    "            pred_batch = {\n",
    "                \"boxes\": output[0].asnumpy()[batch_idx],\n",
    "                \"box_scores\": output[1].asnumpy()[batch_idx],\n",
    "                \"img_id\": int(np.squeeze(img_id[batch_idx])),\n",
    "                \"image_shape\": image_shape[batch_idx]\n",
    "            }\n",
    "            coco_metrics.update(pred_batch)\n",
    "    eval_metrics = coco_metrics.get_metrics()\n",
    "    return eval_metrics\n",
    "\n",
    "\n",
    "def apply_nms(all_boxes, all_scores, thres, max_boxes):\n",
    "    \"\"\"Apply NMS to bboxes.\"\"\"\n",
    "    y1 = all_boxes[:, 0]\n",
    "    x1 = all_boxes[:, 1]\n",
    "    y2 = all_boxes[:, 2]\n",
    "    x2 = all_boxes[:, 3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\n",
    "    order = all_scores.argsort()[::-1]\n",
    "    keep = []\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        if len(keep) >= max_boxes:\n",
    "            break\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thres)[0]\n",
    "\n",
    "        order = order[inds + 1]\n",
    "    return keep\n",
    "\n",
    "\n",
    "class COCOMetrics:\n",
    "    \"\"\"Calculate mAP of predicted bboxes.\"\"\"\n",
    "\n",
    "    def __init__(self, anno_json, classes, num_classes, min_score, nms_threshold, max_boxes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = classes\n",
    "        self.min_score = min_score\n",
    "        self.nms_threshold = nms_threshold\n",
    "        self.max_boxes = max_boxes\n",
    "\n",
    "        self.val_cls_dict = {i: cls for i, cls in enumerate(classes)}\n",
    "        self.coco_gt = COCO(anno_json)\n",
    "        cat_ids = self.coco_gt.loadCats(self.coco_gt.getCatIds())\n",
    "        self.class_dict = {cat['name']: cat['id'] for cat in cat_ids}\n",
    "\n",
    "        self.predictions = []\n",
    "        self.img_ids = []\n",
    "\n",
    "    def update(self, batch):\n",
    "        pred_boxes = batch['boxes']\n",
    "        box_scores = batch['box_scores']\n",
    "        img_id = batch['img_id']\n",
    "        h, w = batch['image_shape']\n",
    "\n",
    "        final_boxes = []\n",
    "        final_label = []\n",
    "        final_score = []\n",
    "        self.img_ids.append(img_id)\n",
    "\n",
    "        for c in range(1, self.num_classes):\n",
    "            class_box_scores = box_scores[:, c]\n",
    "            score_mask = class_box_scores > self.min_score\n",
    "            class_box_scores = class_box_scores[score_mask]\n",
    "            class_boxes = pred_boxes[score_mask] * [h, w, h, w]\n",
    "\n",
    "            if score_mask.any():\n",
    "                nms_index = apply_nms(class_boxes, class_box_scores, self.nms_threshold, self.max_boxes)\n",
    "                class_boxes = class_boxes[nms_index]\n",
    "                class_box_scores = class_box_scores[nms_index]\n",
    "\n",
    "                final_boxes += class_boxes.tolist()\n",
    "                final_score += class_box_scores.tolist()\n",
    "                final_label += [self.class_dict[self.val_cls_dict[c]]] * len(class_box_scores)\n",
    "\n",
    "        for loc, label, score in zip(final_boxes, final_label, final_score):\n",
    "            res = {}\n",
    "            res['image_id'] = img_id\n",
    "            res['bbox'] = [loc[1], loc[0], loc[3] - loc[1], loc[2] - loc[0]]\n",
    "            res['score'] = score\n",
    "            res['category_id'] = label\n",
    "            self.predictions.append(res)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        with open('predictions.json', 'w') as f:\n",
    "            json.dump(self.predictions, f)\n",
    "\n",
    "        coco_dt = self.coco_gt.loadRes('predictions.json')\n",
    "        E = COCOeval(self.coco_gt, coco_dt, iouType='bbox')\n",
    "        E.params.imgIds = self.img_ids\n",
    "        E.evaluate()\n",
    "        E.accumulate()\n",
    "        E.summarize()\n",
    "        return E.stats[0]\n",
    "\n",
    "class SsdInferWithDecoder(nn.Cell):\n",
    "    \"\"\"\n",
    "    SSD Infer wrapper to decode the bbox locations.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): the origin ssd infer network without bbox decoder.\n",
    "        default_boxes (Tensor): the default_boxes from anchor generator\n",
    "        config (dict): ssd config\n",
    "    Returns:\n",
    "        Tensor, the locations for bbox after decoder representing (y0,x0,y1,x1)\n",
    "        Tensor, the prediction labels.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, network, default_boxes, config):\n",
    "        super(SsdInferWithDecoder, self).__init__()\n",
    "        self.network = network\n",
    "        self.default_boxes = default_boxes\n",
    "        self.prior_scaling_xy = config.prior_scaling[0]\n",
    "        self.prior_scaling_wh = config.prior_scaling[1]\n",
    "\n",
    "    def construct(self, x):\n",
    "        pred_loc, pred_label = self.network(x)\n",
    "\n",
    "        default_bbox_xy = self.default_boxes[..., :2]\n",
    "        default_bbox_wh = self.default_boxes[..., 2:]\n",
    "        pred_xy = pred_loc[..., :2] * self.prior_scaling_xy * default_bbox_wh + default_bbox_xy\n",
    "        pred_wh = ops.Exp()(pred_loc[..., 2:] * self.prior_scaling_wh) * default_bbox_wh\n",
    "\n",
    "        pred_xy_0 = pred_xy - pred_wh / 2.0\n",
    "        pred_xy_1 = pred_xy + pred_wh / 2.0\n",
    "        pred_xy = ops.Concat(-1)((pred_xy_0, pred_xy_1))\n",
    "        pred_xy = ops.Maximum()(pred_xy, 0)\n",
    "        pred_xy = ops.Minimum()(pred_xy, 1)\n",
    "        return pred_xy, pred_label\n",
    "    \n",
    "    \n",
    "class EvalCallBack(Callback):\n",
    "    \"\"\"\n",
    "    Evaluation callback when training.\n",
    "\n",
    "    Args:\n",
    "        eval_function (function): evaluation function.\n",
    "        eval_param_dict (dict): evaluation parameters' configure dict.\n",
    "        interval (int): run evaluation interval, default is 1.\n",
    "        eval_start_epoch (int): evaluation start epoch, default is 1.\n",
    "        save_best_ckpt (bool): Whether to save best checkpoint, default is True.\n",
    "        besk_ckpt_name (str): bast checkpoint name, default is `best.ckpt`.\n",
    "        metrics_name (str): evaluation metrics name, default is `acc`.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Examples:\n",
    "        >>> EvalCallBack(eval_function, eval_param_dict)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eval_function, eval_param_dict, interval=1, eval_start_epoch=1, save_best_ckpt=True,\n",
    "                 ckpt_directory=\"./\", besk_ckpt_name=\"best.ckpt\", metrics_name=\"acc\"):\n",
    "        super(EvalCallBack, self).__init__()\n",
    "        self.eval_param_dict = eval_param_dict\n",
    "        self.eval_function = eval_function\n",
    "        self.eval_start_epoch = eval_start_epoch\n",
    "        if interval < 1:\n",
    "            raise ValueError(\"interval should >= 1.\")\n",
    "        self.interval = interval\n",
    "        self.save_best_ckpt = save_best_ckpt\n",
    "        self.best_res = 0\n",
    "        self.best_epoch = 0\n",
    "        if not os.path.isdir(ckpt_directory):\n",
    "            os.makedirs(ckpt_directory)\n",
    "        self.bast_ckpt_path = os.path.join(ckpt_directory, besk_ckpt_name)\n",
    "        self.metrics_name = metrics_name\n",
    "\n",
    "    def remove_ckpoint_file(self, file_name):\n",
    "        \"\"\"Remove the specified checkpoint file from this checkpoint manager and also from the directory.\"\"\"\n",
    "        try:\n",
    "            os.chmod(file_name, stat.S_IWRITE)\n",
    "            os.remove(file_name)\n",
    "        except OSError:\n",
    "            logger.warning(\"OSError, failed to remove the older ckpt file %s.\", file_name)\n",
    "        except ValueError:\n",
    "            logger.warning(\"ValueError, failed to remove the older ckpt file %s.\", file_name)\n",
    "\n",
    "    def epoch_end(self, run_context):\n",
    "        \"\"\"Callback when epoch end.\"\"\"\n",
    "        cb_params = run_context.original_args()\n",
    "        cur_epoch = cb_params.cur_epoch_num\n",
    "        if cur_epoch >= self.eval_start_epoch and (cur_epoch - self.eval_start_epoch) % self.interval == 0:\n",
    "            res = self.eval_function(self.eval_param_dict)\n",
    "            print(\"epoch: {}, {}: {}\".format(cur_epoch, self.metrics_name, res), flush=True)\n",
    "            if res >= self.best_res:\n",
    "                self.best_res = res\n",
    "                self.best_epoch = cur_epoch\n",
    "                print(\"update best result: {}\".format(res), flush=True)\n",
    "                if self.save_best_ckpt:\n",
    "                    if os.path.exists(self.bast_ckpt_path):\n",
    "                        self.remove_ckpoint_file(self.bast_ckpt_path)\n",
    "                    save_checkpoint(cb_params.train_network, self.bast_ckpt_path)\n",
    "                    print(\"update best checkpoint at: {}\".format(self.bast_ckpt_path), flush=True)\n",
    "\n",
    "    def end(self, run_context):\n",
    "        print(\"End training, the best {0} is: {1}, the best {0} epoch is {2}\".format(self.metrics_name,\n",
    "                                                                                     self.best_res,\n",
    "                                                                                     self.best_epoch), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e45a95",
   "metadata": {},
   "source": [
    "### 训练过程\n",
    "a）先验框匹配  \n",
    "在训练过程中，首先要确定训练图片中的ground truth（真实目标）与哪个先验框来进行匹配，与之匹配的先验框所对应的边界框将负责预测它。在Yolo中，ground truth的中心落在哪个单元格，该单元格中与其IOU最大的边界框负责预测它。但是在SSD中却完全不一样，SSD的先验框与ground truth的匹配原则主要有两点。首先，对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本（其实应该是先验框对应的预测box，不过由于是一一对应的就这样称呼了），反之，若一个先验框没有与任何ground truth进行匹配，那么该先验框只能与背景匹配，就是负样本。一个图片中ground truth是非常少的， 而先验框却很多，如果仅按第一个原则匹配，很多先验框会是负样本，正负样本极其不平衡，所以需要第二个原则。第二个原则是：对于剩余的未匹配先验框，若某个ground truth的  大于某个阈值（一般是0.5），那么该先验框也与这个ground truth进行匹配。这意味着某个ground truth可能与多个先验框匹配，这是可以的。但是反过来却不可以，因为一个先验框只能匹配一个ground truth，如果多个ground truth与某个先验框  大于阈值，那么先验框只与IOU最大的那个ground truth进行匹配。第二个原则一定在第一个原则之后进行，仔细考虑一下这种情况，如果某个ground truth所对应最大  小于阈值，并且所匹配的先验框却与另外一个ground truth的  大于阈值，那么该先验框应该匹配谁，答案应该是前者，首先要确保某个ground truth一定有一个先验框与之匹配。但是，这种情况我觉得基本上是不存在的。由于先验框很多，某个ground truth的最大  肯定大于阈值，所以可能只实施第二个原则既可以了，这里的TensorFlow版本就是只实施了第二个原则，但是这里的Pytorch两个原则都实施了。图8为一个匹配示意图，其中绿色的GT是ground truth，红色为先验框，FP表示负样本，TP表示正样本。  \n",
    "尽管一个ground truth可以与多个先验框匹配，但是ground truth相对先验框还是太少了，所以负样本相对正样本会很多。为了保证正负样本尽量平衡，SSD采用了hard negative mining，就是对负样本进行抽样，抽样时按照置信度误差（预测背景的置信度越小，误差越大）进行降序排列，选取误差的较大的top-k作为训练的负样本，以保证正负样本比例接近1:3。\n",
    "### 预测过程  \n",
    "预测过程比较简单，对于每个预测框，首先根据类别置信度确定其类别（置信度最大者）与置信度值，并过滤掉属于背景的预测框。然后根据置信度阈值（如0.5）过滤掉阈值较低的预测框。对于留下的预测框进行解码，根据先验框得到其真实的位置参数（解码后一般还需要做clip，防止预测框位置超出图片）。解码之后，一般需要根据置信度进行降序排列，然后仅保留top-k（如400）个预测框。最后就是进行NMS算法，过滤掉那些重叠度较大的预测框。最后剩余的预测框就是检测结果了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d3a78",
   "metadata": {},
   "source": [
    "### 训练SSDNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c5f05d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(8347:139690630174528,MainProcess):2022-09-17-20:49:03.662.125 [mindspore/train/model.py:1077] For EvalCallBack callback, {'end', 'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord0\n",
      "In sink mode, one epoch return a loss.\n",
      "epoch: 1 step: 9, loss is 184.18634033203125\n",
      "Train epoch time: 8592.946 ms, per step time: 954.772 ms\n",
      "epoch: 2 step: 9, loss is 31.391172409057617\n",
      "Train epoch time: 1444.524 ms, per step time: 160.503 ms\n",
      "epoch: 3 step: 9, loss is 32.29104995727539\n",
      "Train epoch time: 1472.339 ms, per step time: 163.593 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:15.189.553 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:15.189.577 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:15.236.956 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:15.236.967 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:15.244.840 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:15.244.851 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n",
      "epoch: 3, mAP: 0.003886689955656808\n",
      "update best result: 0.003886689955656808\n",
      "update best checkpoint at: ./cache/train/ckpt_0/best_map.ckpt\n",
      "epoch: 4 step: 9, loss is 115.91234588623047\n",
      "Train epoch time: 1727.417 ms, per step time: 191.935 ms\n",
      "epoch: 5 step: 9, loss is 51.22126007080078\n",
      "Train epoch time: 1599.364 ms, per step time: 177.707 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:21.374.270 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:21.374.284 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:21.383.988 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:21.384.002 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n",
      "epoch: 5, mAP: 0.005947975214167317\n",
      "update best result: 0.005947975214167317\n",
      "update best checkpoint at: ./cache/train/ckpt_0/best_map.ckpt\n",
      "epoch: 6 step: 9, loss is 40.63396453857422\n",
      "Train epoch time: 1441.991 ms, per step time: 160.221 ms\n",
      "epoch: 7 step: 9, loss is 41.56122589111328\n",
      "Train epoch time: 1454.225 ms, per step time: 161.581 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:26.033.543 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:26.033.559 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:26.040.093 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:26.040.106 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.18s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
      "epoch: 7, mAP: 0.0006815642493635403\n",
      "epoch: 8 step: 9, loss is 25.979202270507812\n",
      "Train epoch time: 1423.985 ms, per step time: 158.221 ms\n",
      "epoch: 9 step: 9, loss is 17.201229095458984\n",
      "Train epoch time: 1488.570 ms, per step time: 165.397 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:30.127.731 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:30.127.747 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:30.135.764 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:30.135.777 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.11s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.189\n",
      "epoch: 9, mAP: 0.0007992436298952127\n",
      "epoch: 10 step: 9, loss is 8.564105033874512\n",
      "Train epoch time: 2332.773 ms, per step time: 259.197 ms\n",
      "epoch: 11 step: 9, loss is 6.898349285125732\n",
      "Train epoch time: 1431.409 ms, per step time: 159.045 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:35.284.079 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:35.284.093 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:35.291.281 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:35.291.291 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.133\n",
      "epoch: 11, mAP: 0.0007258577331786178\n",
      "epoch: 12 step: 9, loss is 7.758799076080322\n",
      "Train epoch time: 1429.584 ms, per step time: 158.843 ms\n",
      "epoch: 13 step: 9, loss is 8.64794921875\n",
      "Train epoch time: 1440.666 ms, per step time: 160.074 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:42.706.215 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:42.706.230 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:42.713.283 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:42.713.298 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.306\n",
      "epoch: 13, mAP: 0.0009230106671111848\n",
      "epoch: 14 step: 9, loss is 6.995001792907715\n",
      "Train epoch time: 1430.005 ms, per step time: 158.889 ms\n",
      "epoch: 15 step: 9, loss is 7.267788887023926\n",
      "Train epoch time: 1442.139 ms, per step time: 160.238 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:50.087.959 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:50.087.973 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:50.094.818 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:50.094.839 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.19s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.43s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.139\n",
      "epoch: 15, mAP: 0.0005515860889059429\n",
      "epoch: 16 step: 9, loss is 8.399978637695312\n",
      "Train epoch time: 1634.826 ms, per step time: 181.647 ms\n",
      "epoch: 17 step: 9, loss is 9.603084564208984\n",
      "Train epoch time: 1547.214 ms, per step time: 171.913 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:57.941.424 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:49:57.941.438 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:57.950.213 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:49:57.950.230 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.38s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.090\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.128\n",
      "epoch: 17, mAP: 0.00142444360049103\n",
      "epoch: 18 step: 9, loss is 6.171914100646973\n",
      "Train epoch time: 1449.955 ms, per step time: 161.106 ms\n",
      "epoch: 19 step: 9, loss is 5.503366947174072\n",
      "Train epoch time: 1600.223 ms, per step time: 177.803 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:05.005.470 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:05.005.485 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:05.013.068 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:05.013.081 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.17s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.37s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
      "epoch: 19, mAP: 0.0005799356140645055\n",
      "epoch: 20 step: 9, loss is 6.884487628936768\n",
      "Train epoch time: 2414.296 ms, per step time: 268.255 ms\n",
      "epoch: 21 step: 9, loss is 6.644925117492676\n",
      "Train epoch time: 1488.723 ms, per step time: 165.414 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:12.561.315 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:12.561.331 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:12.568.051 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:12.568.063 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.067\n",
      "epoch: 21, mAP: 0.0013416534188295292\n",
      "epoch: 22 step: 9, loss is 6.85774040222168\n",
      "Train epoch time: 1510.293 ms, per step time: 167.810 ms\n",
      "epoch: 23 step: 9, loss is 7.024138450622559\n",
      "Train epoch time: 1677.483 ms, per step time: 186.387 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:19.064.268 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:19.064.282 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:19.070.677 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:19.070.688 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.053\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "epoch: 23, mAP: 0.002399874789046141\n",
      "epoch: 24 step: 9, loss is 7.182035446166992\n",
      "Train epoch time: 1504.839 ms, per step time: 167.204 ms\n",
      "epoch: 25 step: 9, loss is 6.919562339782715\n",
      "Train epoch time: 1555.728 ms, per step time: 172.859 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:24.923.006 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:24.923.020 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:24.930.150 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:24.930.163 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.067\n",
      "epoch: 25, mAP: 0.002006423783738039\n",
      "epoch: 26 step: 9, loss is 5.887188911437988\n",
      "Train epoch time: 1439.017 ms, per step time: 159.891 ms\n",
      "epoch: 27 step: 9, loss is 5.946597099304199\n",
      "Train epoch time: 1445.114 ms, per step time: 160.568 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:30.782.739 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:30.782.753 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:30.789.976 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:30.789.986 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      "epoch: 27, mAP: 0.0012009176195825935\n",
      "epoch: 28 step: 9, loss is 5.794462203979492\n",
      "Train epoch time: 1491.685 ms, per step time: 165.743 ms\n",
      "epoch: 29 step: 9, loss is 6.221961975097656\n",
      "Train epoch time: 1558.765 ms, per step time: 173.196 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:36.550.668 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:36.550.682 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:36.557.217 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:36.557.235 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.37s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
      "epoch: 29, mAP: 0.0011038851615101503\n",
      "epoch: 30 step: 9, loss is 5.544665813446045\n",
      "Train epoch time: 2458.884 ms, per step time: 273.209 ms\n",
      "epoch: 31 step: 9, loss is 5.128056049346924\n",
      "Train epoch time: 1474.658 ms, per step time: 163.851 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:43.294.408 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:43.294.423 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:43.300.995 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:43.301.008 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
      "epoch: 31, mAP: 0.011996993980213446\n",
      "update best result: 0.011996993980213446\n",
      "update best checkpoint at: ./cache/train/ckpt_0/best_map.ckpt\n",
      "epoch: 32 step: 9, loss is 6.746145725250244\n",
      "Train epoch time: 1481.017 ms, per step time: 164.557 ms\n",
      "epoch: 33 step: 9, loss is 5.385143280029297\n",
      "Train epoch time: 1499.328 ms, per step time: 166.592 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:50.046.272 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:50.046.287 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:50.052.687 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:50.052.697 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n",
      "epoch: 33, mAP: 0.006422464752061225\n",
      "epoch: 34 step: 9, loss is 6.027894496917725\n",
      "Train epoch time: 2350.551 ms, per step time: 261.172 ms\n",
      "epoch: 35 step: 9, loss is 5.126617431640625\n",
      "Train epoch time: 1586.047 ms, per step time: 176.227 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:56.558.831 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:50:56.558.854 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:56.565.735 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:50:56.565.746 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.283\n",
      "epoch: 35, mAP: 0.006953041532133368\n",
      "epoch: 36 step: 9, loss is 4.970442771911621\n",
      "Train epoch time: 1452.903 ms, per step time: 161.434 ms\n",
      "epoch: 37 step: 9, loss is 5.516609191894531\n",
      "Train epoch time: 1473.421 ms, per step time: 163.713 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:02.313.755 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:02.313.769 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:02.320.206 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:02.320.217 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.209\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
      "epoch: 37, mAP: 0.012785285914568208\n",
      "update best result: 0.012785285914568208\n",
      "update best checkpoint at: ./cache/train/ckpt_0/best_map.ckpt\n",
      "epoch: 38 step: 9, loss is 5.455641746520996\n",
      "Train epoch time: 1466.818 ms, per step time: 162.980 ms\n",
      "epoch: 39 step: 9, loss is 5.0634660720825195\n",
      "Train epoch time: 1510.169 ms, per step time: 167.797 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:08.858.774 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:08.858.806 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:08.865.687 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:08.865.699 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.35s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.103\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      "epoch: 39, mAP: 0.0026330962796711323\n",
      "epoch: 40 step: 9, loss is 5.255551338195801\n",
      "Train epoch time: 2516.724 ms, per step time: 279.636 ms\n",
      "epoch: 41 step: 9, loss is 4.863509178161621\n",
      "Train epoch time: 1443.890 ms, per step time: 160.432 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:15.617.544 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:15.617.558 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:15.625.080 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:15.625.090 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
      "epoch: 41, mAP: 0.003806822116645724\n",
      "epoch: 42 step: 9, loss is 5.49976921081543\n",
      "Train epoch time: 1438.482 ms, per step time: 159.831 ms\n",
      "epoch: 43 step: 9, loss is 5.738044738769531\n",
      "Train epoch time: 1449.563 ms, per step time: 161.063 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:20.976.517 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:20.976.534 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:20.983.063 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:20.983.075 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.289\n",
      "epoch: 43, mAP: 0.0054297801425740875\n",
      "epoch: 44 step: 9, loss is 5.338379383087158\n",
      "Train epoch time: 1484.214 ms, per step time: 164.913 ms\n",
      "epoch: 45 step: 9, loss is 5.867029190063477\n",
      "Train epoch time: 1514.428 ms, per step time: 168.270 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:26.387.902 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:26.387.917 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:26.394.345 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:26.394.355 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.021\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.328\n",
      "epoch: 45, mAP: 0.004522133007486115\n",
      "epoch: 46 step: 9, loss is 5.245680809020996\n",
      "Train epoch time: 1499.174 ms, per step time: 166.575 ms\n",
      "epoch: 47 step: 9, loss is 4.797170162200928\n",
      "Train epoch time: 1568.787 ms, per step time: 174.310 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:31.745.084 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:31.745.098 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:31.751.472 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:31.751.482 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.37s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      "epoch: 47, mAP: 0.0051256174244388416\n",
      "epoch: 48 step: 9, loss is 4.841647624969482\n",
      "Train epoch time: 1494.651 ms, per step time: 166.072 ms\n",
      "epoch: 49 step: 9, loss is 6.16235876083374\n",
      "Train epoch time: 1553.144 ms, per step time: 172.572 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:37.142.262 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:37.142.277 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:37.148.744 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:37.148.754 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.090\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n",
      "epoch: 49, mAP: 0.006022924570728136\n",
      "epoch: 50 step: 9, loss is 6.61398983001709\n",
      "Train epoch time: 2497.488 ms, per step time: 277.499 ms\n",
      "epoch: 51 step: 9, loss is 5.155490875244141\n",
      "Train epoch time: 1507.638 ms, per step time: 167.515 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:43.299.631 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:43.299.645 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:43.306.479 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:43.306.490 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.42s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "epoch: 51, mAP: 0.0023902682133490885\n",
      "epoch: 52 step: 9, loss is 6.151439189910889\n",
      "Train epoch time: 1454.126 ms, per step time: 161.570 ms\n",
      "epoch: 53 step: 9, loss is 4.965357780456543\n",
      "Train epoch time: 1469.280 ms, per step time: 163.253 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:48.495.176 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:48.495.190 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:48.501.584 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:48.501.594 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.087\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "epoch: 53, mAP: 0.0017485997244517325\n",
      "epoch: 54 step: 9, loss is 5.8200788497924805\n",
      "Train epoch time: 1447.461 ms, per step time: 160.829 ms\n",
      "epoch: 55 step: 9, loss is 5.713700294494629\n",
      "Train epoch time: 1503.582 ms, per step time: 167.065 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:53.679.568 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:53.679.581 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:53.685.891 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:53.685.901 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "epoch: 55, mAP: 0.0026831262060854452\n",
      "epoch: 56 step: 9, loss is 6.265634536743164\n",
      "Train epoch time: 1501.554 ms, per step time: 166.839 ms\n",
      "epoch: 57 step: 9, loss is 5.7522125244140625\n",
      "Train epoch time: 1560.037 ms, per step time: 173.337 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:58.942.047 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:51:58.942.061 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:58.948.541 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:51:58.948.552 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.12s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "epoch: 57, mAP: 0.003188246742459634\n",
      "epoch: 58 step: 9, loss is 5.137873649597168\n",
      "Train epoch time: 1559.607 ms, per step time: 173.290 ms\n",
      "epoch: 59 step: 9, loss is 4.989060401916504\n",
      "Train epoch time: 1501.800 ms, per step time: 166.867 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:52:04.244.065 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f0c4263d740,python):2022-09-17-20:52:04.244.080 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:52:04.250.607 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(8347,7f09297fe700,python):2022-09-17-20:52:04.250.617 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord4 does not contain any samples, pls remove it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.15s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.026\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "epoch: 59, mAP: 0.0026064633346603214\n",
      "epoch: 60 step: 9, loss is 5.308234214782715\n",
      "Train epoch time: 2675.660 ms, per step time: 297.296 ms\n",
      "End training, the best mAP is: 0.012785285914568208, the best mAP epoch is 37\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mindspore.train import Model\n",
    "from mindspore.context import ParallelMode\n",
    "# from src.ssd import   SsdInferWithDecoder, SSDWithLossCell, TrainingWrapper,ssd_vgg16\n",
    "from src.config import get_config\n",
    "import mindspore as ms\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, LossMonitor, TimeMonitor\n",
    "from src.init_params import init_net_param\n",
    "from src.lr_schedule import get_lr\n",
    "from mindspore.common import set_seed, dtype\n",
    "from src.box_utils import default_boxes\n",
    "\n",
    "class TrainingWrapper(nn.Cell):\n",
    "    \"\"\"\n",
    "    Encapsulation class of SSD network training.\n",
    "\n",
    "    Append an optimizer to the training network after that the construct\n",
    "    function can be called to create the backward graph.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): The training network. Note that loss function should have been added.\n",
    "        optimizer (Optimizer): Optimizer for updating the weights.\n",
    "        sens (Number): The adjust parameter. Default: 1.0.\n",
    "        use_global_nrom(bool): Whether apply global norm before optimizer. Default: False\n",
    "    \"\"\"\n",
    "    def __init__(self, network, optimizer, sens=1.0, use_global_norm=False):\n",
    "        super(TrainingWrapper, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.network.set_grad()\n",
    "        self.weights = ms.ParameterTuple(network.trainable_params())\n",
    "        self.optimizer = optimizer\n",
    "        self.grad = ops.GradOperation(get_by_list=True, sens_param=True)\n",
    "        self.sens = sens\n",
    "        self.reducer_flag = False\n",
    "        self.grad_reducer = None\n",
    "        self.use_global_norm = use_global_norm\n",
    "        self.parallel_mode = ms.get_auto_parallel_context(\"parallel_mode\")\n",
    "        if self.parallel_mode in [ParallelMode.DATA_PARALLEL, ParallelMode.HYBRID_PARALLEL]:\n",
    "            self.reducer_flag = True\n",
    "        if self.reducer_flag:\n",
    "            mean = ms.get_auto_parallel_context(\"gradients_mean\")\n",
    "            if auto_parallel_context().get_device_num_is_set():\n",
    "                degree = ms.get_auto_parallel_context(\"device_num\")\n",
    "            else:\n",
    "                degree = get_group_size()\n",
    "            self.grad_reducer = nn.DistributedGradReducer(optimizer.parameters, mean, degree)\n",
    "        self.hyper_map = ops.HyperMap()\n",
    "\n",
    "    def construct(self, *args):\n",
    "        weights = self.weights\n",
    "        loss = self.network(*args)\n",
    "        sens = ops.Fill()(ops.DType()(loss), ops.Shape()(loss), self.sens)\n",
    "        grads = self.grad(self.network, weights)(*args, sens)\n",
    "        if self.reducer_flag:\n",
    "            # apply grad reducer on grads\n",
    "            grads = self.grad_reducer(grads)\n",
    "        if self.use_global_norm:\n",
    "            grads = self.hyper_map(ops.partial(grad_scale, ops.scalar_to_array(self.sens)), grads)\n",
    "            grads = ops.clip_by_global_norm(grads)\n",
    "        self.optimizer(grads)\n",
    "        return loss\n",
    "\n",
    "\n",
    "set_seed(1)\n",
    "#自定义参数获取\n",
    "config = get_config()\n",
    "rank = 0\n",
    "# device_num = 1\n",
    "loss_scale = float(config.loss_scale)\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target=config.device_target)\n",
    "prefix=\"ssd.mindrecord\"\n",
    "\n",
    "#数据加载\n",
    "mindrecord_dir = os.path.join(config.data_path, config.mindrecord_dir)\n",
    "mindrecord_file = os.path.join(mindrecord_dir, prefix + \"0\")\n",
    "\n",
    "dataset = create_ssd_dataset(mindrecord_file, batch_size=config.batch_size,\n",
    "                             rank=rank, use_multiprocessing=True)\n",
    "\n",
    "dataset_size = dataset.get_dataset_size()\n",
    "\n",
    "# checkpoint\n",
    "ckpt_config = CheckpointConfig(save_checkpoint_steps=dataset_size * config.save_checkpoint_epochs)\n",
    "ckpt_save_dir = config.output_path +'/ckpt_{}/'.format(rank)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"ssd\", directory=ckpt_save_dir, config=ckpt_config)\n",
    "\n",
    "\n",
    "#网络定义与初始化\n",
    "ssd = ssd_vgg16(config=config)\n",
    "init_net_param(ssd)\n",
    "# print(ssd)\n",
    "net = SSDWithLossCell(ssd, config)\n",
    "# print(net)\n",
    "lr = Tensor(get_lr(global_step=config.pre_trained_epoch_size * dataset_size,\n",
    "                   lr_init=config.lr_init, lr_end=config.lr_end_rate * config.lr, lr_max=config.lr,\n",
    "                   warmup_epochs=config.warmup_epochs,\n",
    "                   total_epochs=config.epoch_size,\n",
    "                   steps_per_epoch=dataset_size))\n",
    "opt = nn.Momentum(filter(lambda x: x.requires_grad, net.get_parameters()), lr,\n",
    "                  config.momentum, config.weight_decay, loss_scale)\n",
    "net = TrainingWrapper(net, opt, loss_scale)\n",
    "\n",
    "callback = [TimeMonitor(data_size=dataset_size), LossMonitor(), ckpoint_cb]\n",
    "\n",
    "#评估\n",
    "if config.run_eval:\n",
    "    eval_net = SsdInferWithDecoder(ssd, Tensor(default_boxes), config)\n",
    "    eval_net.set_train(False)\n",
    "#     mindrecord_file = create_mindrecord(config.dataset, \"ssd_eval.mindrecord\", False)\n",
    "    \n",
    "    eval_prefix = \"ssd_eval.mindrecord\"\n",
    "    eval_mindrecord_dir = os.path.join(config.data_path, config.mindrecord_dir)\n",
    "    eval_mindrecord_file = os.path.join(eval_mindrecord_dir, eval_prefix + \"0\")\n",
    "    eval_dataset = create_ssd_dataset(eval_mindrecord_file, batch_size=config.batch_size,\n",
    "                                      is_training=False, use_multiprocessing=False)\n",
    "    if config.dataset == \"coco\":\n",
    "        anno_json = os.path.join(config.coco_root, config.instances_set.format(config.val_data_type))\n",
    "    eval_param_dict = {\"net\": eval_net, \"dataset\": eval_dataset, \"anno_json\": anno_json}\n",
    "    eval_cb = EvalCallBack(apply_eval, eval_param_dict, interval=config.eval_interval,\n",
    "                           eval_start_epoch=config.eval_start_epoch, save_best_ckpt=True,\n",
    "                           ckpt_directory=ckpt_save_dir, besk_ckpt_name=\"best_map.ckpt\",\n",
    "                           metrics_name=\"mAP\")\n",
    "    callback.append(eval_cb)\n",
    "\n",
    "model = Model(net)\n",
    "dataset_sink_mode = False\n",
    "if config.mode_sink == \"sink\" and config.device_target != \"CPU\":\n",
    "    print(\"In sink mode, one epoch return a loss.\")\n",
    "    dataset_sink_mode = True\n",
    "# print(\"Start train SSD, the first epoch will be slower because of the graph compilation.\")\n",
    "model.train(config.epoch_size, dataset, callbacks=callback, dataset_sink_mode=dataset_sink_mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
