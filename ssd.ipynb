{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2a9205",
   "metadata": {},
   "source": [
    "# 基于MindSpore框架的SSD案例实现\n",
    "## 1 模型简介\n",
    "SSD模型于2016年在论文《SSD: Single Shot MultiBox Detector》中被提出。SSD是单阶段的目标检测算法，通过卷积神经网络进行特征提取，取不同的特征层进行检测输出，所以SSD是一种多尺度的检测方法。  \n",
    "在需要检测的特征层，直接使用一个3$\\times$3卷积，进行通道的变换。SSD采用了anchor的策略，预设不同长宽比例的anchor，每一个输出特征层基于anchor预测多个检测框（4或者6）。采用了多尺度检测方法，在浅层用于检测小目标，深层用于检测大目标。\n",
    "\n",
    "\n",
    "\n",
    "### 1.1 模型结构\n",
    "SSD采用VGG16作为基础模型，然后在VGG16的基础上新增了卷积层来获得更多的特征图以用于检测。SSD的网络结构如图1所示。上面是SSD模型，下面是Yolo模型，可以明显看到SSD利用了多尺度的特征图做检测。模型的输入图片大小是300$\\times$300（还可以是512$\\times$512，其与前者网络结构没有差别，只是最后新增一个卷积层）。  \n",
    "  \n",
    "![图片](./src/img/v2-a43295a3e146008b2131b160eec09cd4_r.jpg)\n",
    "\n",
    "图1 两种单阶段目标检测算法的比较  \n",
    "\n",
    "SSD先通过卷积不断进行特征提取，在需要检测物体的网络，直接通过一个3$\\times$3卷积得到输出，卷积的通道数由anchor数量和类别数量决定，具体为(anchor数量*(类别数量+4))。\n",
    "SSD对比了YOLO系列目标检测方法，不同的是SSD通过卷积得到最后的边界框，而YOLO对最后的输出采用全连接的形式得到一维向量，对向量进行拆解得到最终的检测框。\n",
    "### 1.2 模型特点\n",
    "  \n",
    "a)多尺度检测  \n",
    "在SSD的网络结构图中我们可以看到，SSD使用了多个特征层，特征层的尺寸分别是38$\\times$38，19$\\times$19，10$\\times$10，5$\\times$5，3$\\times$3，1$\\times$1，一共6种不同的特征图尺寸。大尺度特征图（较靠前的特征图）可以用来检测小物体，而小尺度特征图（较靠后的特征图）用来检测大物体。多尺度检测的方式，可以使得检测更加充分（SSD属于密集检测），更能检测出小目标。  \n",
    "\n",
    "b)采用卷积进行检测  \n",
    "与Yolo最后采用全连接层不同，SSD直接采用卷积对不同的特征图来进行提取检测结果。对于形状为m$\\times$n$\\times$p的特征图，只需要采用3$\\times$3$\\times$p这样比较小的卷积核得到检测值。  \n",
    "\n",
    "c)预设anchor\n",
    "在yolov1中，直接由网络预测目标的尺寸，这种方式使得预测框的长宽比和尺寸没有限制，难以训练。在SSD中，采用预设边界框，我们习惯称它为anchor（在SSD论文中叫default bounding boxes），预测框的尺寸在anchor的指导下进行微调。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28267d5",
   "metadata": {},
   "source": [
    "## 2 案例实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095ccaa",
   "metadata": {},
   "source": [
    "### 2.1 环境准备与数据读取\n",
    "本案例基于MindSpore-GPU 1.8.1版本实现，在GPU上完成模型训练。  \n",
    "  \n",
    "案例所使用的数据为coco2017，下载链接，考虑到原始数据集过大，从中随机划分出100张图像作为训练集tiny_train_coco2017(下载链接)，50张图像作为测试集tiny_val_coco2017（下载链接），且将数据转换为了Mindrecord格式（下载链接）。  \n",
    "\n",
    "数据集包含训练集、验证集以及对应的json文件，目录结构如下：  \n",
    "\n",
    "└─tiny_coco2017  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─annotations  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─instance_train2017.json  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└─instance_val2017.json  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─val2017  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;└─train2017  \n",
    "\n",
    "#### 为了更加方便地保存和加载数据，本案例中在数据读取前首先将coco数据集转换成MindRecord格式：MindRecord_COCO（下载链接）  \n",
    "MindRecord目录结构如下：  \n",
    "└─MindRecord_COCO  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd.mindrecord0  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd.mindrecord0.db  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd.mindrecord1  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd.mindrecord1.db   \n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd_eval.mindrecord0  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd_eval.mindrecord0.db  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd_eval.mindrecord1  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;├─ssd_eval.mindrecord1.db   \n",
    " \n",
    "MindSpore中可以把用于训练网络模型的数据集，转换为MindSpore特定的格式数据（MindSpore Record格式），从而更加方便地保存和加载数据。\n",
    "\n",
    "+ mindspore.mindrecord模块中定义了一个专门的类FileWriter可以将用户定义的原始数据写入MindRecord文件。\n",
    "\n",
    "+ 通过MindDataset接口，可以实现MindSpore Record文件的读取。\n",
    "\n",
    "+ 使用MindRecord的目标是归一化提供训练测试所用的数据集，并通过dataset模块的相关方法进行数据的读取，将这些高效的数据投入训练。\n",
    "\n",
    "\n",
    "\n",
    "![图片](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r1.8/tutorials/source_zh_cn/advanced/dataset/images/data_conversion_concept.png)\n",
    "\n",
    "MindRecord具备的特征如下：\n",
    "\n",
    "1. 实现多变的用户数据统一存储、访问，训练数据读取更加简便。\n",
    "2. 数据聚合存储，高效读取，且方便管理、移动。\n",
    "3. 高效的数据编解码操作，对用户透明、无感知。\n",
    "4. 可以灵活控制分区的大小，实现分布式训练。\n",
    "\n",
    "使用MindSpore Record数据格式可以减少磁盘IO、网络IO开销，从而获得更好的使用体验和性能提升。\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64a3a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ssd.mindrecord Mindrecord exists.\n",
      " ssd_eval.mindrecord Mindrecord exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "from src.config import get_config\n",
    "from src.create_coco_label import create_coco_label\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "def data_to_mindrecord_byte_image( is_training=True, prefix=\"ssd.mindrecord\", file_num=8):\n",
    "    \"\"\"Create MindRecord file.\"\"\"\n",
    "    mindrecord_path = os.path.join(config.data_path, config.mindrecord_dir, prefix)\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    images, image_path_dict, image_anno_dict = create_coco_label(is_training)\n",
    "    ssd_json = {\n",
    "        \"img_id\": {\"type\": \"int32\", \"shape\": [1]},\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 5]},\n",
    "    }\n",
    "    writer.add_schema(ssd_json, \"ssd_json\")\n",
    "\n",
    "    for img_id in images:\n",
    "        image_path = image_path_dict[img_id]\n",
    "        with open(image_path, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[img_id], dtype=np.int32)\n",
    "        img_id = np.array([img_id], dtype=np.int32)\n",
    "        row = {\"img_id\": img_id, \"image\": img, \"annotation\": annos}\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def create_mindrecord( prefix=\"ssd.mindrecord\", is_training=True):\n",
    "\n",
    "    mindrecord_dir = os.path.join(config.data_path, config.mindrecord_dir)\n",
    "    mindrecord_file = os.path.join(mindrecord_dir, prefix + \"0\")\n",
    "    os.makedirs(mindrecord_dir,exist_ok=True)\n",
    "    if not os.path.exists(mindrecord_file):\n",
    "        print(\"Create {} Mindrecord.\".format(prefix))\n",
    "        data_to_mindrecord_byte_image(is_training, prefix)\n",
    "        print(\"Create {} Mindrecord Done, at {}\".format(prefix,mindrecord_dir))\n",
    "    else:\n",
    "        print(\" {} Mindrecord exists.\".format(prefix))\n",
    "    return mindrecord_file\n",
    "\n",
    "# 数据转换为mindrecord格式\n",
    "mindrecord_file = create_mindrecord(\"ssd.mindrecord\", True)\n",
    "eval_mindrecord_file = create_mindrecord(\"ssd_eval.mindrecord\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f834043",
   "metadata": {},
   "source": [
    "## 数据预处理  \n",
    "数据统一resize为300$\\times$300大小  \n",
    "SSD算法中采用了以下几种数据增强的方法：  \n",
    "随机裁剪：随机裁剪一个部分，每个采样部分的大小为原图的[0.3,1]，长宽比在1/2和2之间。如果真实标签框的中心位于采样部分内，则保留真实框与图片重叠的部分。  \n",
    "水平翻转：对采样后的小图片进行0.5概率的随机水平翻转 .  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a23487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from src.box_utils import jaccard_numpy, ssd_bboxes_encode\n",
    "\n",
    "def _rand(a=0., b=1.):\n",
    "    return np.random.rand() * (b - a) + a\n",
    "\n",
    "# 随机裁剪图像和box\n",
    "def random_sample_crop(image, boxes):\n",
    "    height, width, _ = image.shape\n",
    "    min_iou = np.random.choice([None, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "    if min_iou is None:\n",
    "        return image, boxes\n",
    "\n",
    "    # max trails (50)\n",
    "    for _ in range(50):\n",
    "        image_t = image\n",
    "        w = _rand(0.3, 1.0) * width\n",
    "        h = _rand(0.3, 1.0) * height\n",
    "        # aspect ratio constraint b/t .5 & 2\n",
    "        if h / w < 0.5 or h / w > 2:\n",
    "            continue\n",
    "\n",
    "        left = _rand() * (width - w)\n",
    "        top = _rand() * (height - h)\n",
    "        rect = np.array([int(top), int(left), int(top + h), int(left + w)])\n",
    "        overlap = jaccard_numpy(boxes, rect)\n",
    "\n",
    "        # dropout some boxes\n",
    "        drop_mask = overlap > 0\n",
    "        if not drop_mask.any():\n",
    "            continue\n",
    "\n",
    "        if overlap[drop_mask].min() < min_iou and overlap[drop_mask].max() > (min_iou + 0.2):\n",
    "            continue\n",
    "\n",
    "        image_t = image_t[rect[0]:rect[2], rect[1]:rect[3], :]\n",
    "        centers = (boxes[:, :2] + boxes[:, 2:4]) / 2.0\n",
    "        m1 = (rect[0] < centers[:, 0]) * (rect[1] < centers[:, 1])\n",
    "        m2 = (rect[2] > centers[:, 0]) * (rect[3] > centers[:, 1])\n",
    "\n",
    "        # mask in that both m1 and m2 are true\n",
    "        mask = m1 * m2 * drop_mask\n",
    "\n",
    "        # have any valid boxes? try again if not\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        # take only matching gt boxes\n",
    "        boxes_t = boxes[mask, :].copy()\n",
    "        boxes_t[:, :2] = np.maximum(boxes_t[:, :2], rect[:2])\n",
    "        boxes_t[:, :2] -= rect[:2]\n",
    "        boxes_t[:, 2:4] = np.minimum(boxes_t[:, 2:4], rect[2:4])\n",
    "        boxes_t[:, 2:4] -= rect[:2]\n",
    "\n",
    "        return image_t, boxes_t\n",
    "    return image, boxes\n",
    "\n",
    "\n",
    "def preprocess_fn(img_id, image, box, is_training):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "    cv2.setNumThreads(2)\n",
    "\n",
    "    def _infer_data(image, input_shape):\n",
    "        img_h, img_w, _ = image.shape\n",
    "        input_h, input_w = input_shape\n",
    "\n",
    "        image = cv2.resize(image, (input_w, input_h))\n",
    "\n",
    "        # When the channels of image is 1\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            image = np.concatenate([image, image, image], axis=-1)\n",
    "\n",
    "        return img_id, image, np.array((img_h, img_w), np.float32)\n",
    "\n",
    "    def _data_aug(image, box, is_training, image_size=(300, 300)):\n",
    "        ih, iw, _ = image.shape\n",
    "        h, w = image_size\n",
    "        if not is_training:\n",
    "            return _infer_data(image, image_size)\n",
    "        # Random crop\n",
    "        box = box.astype(np.float32)\n",
    "        image, box = random_sample_crop(image, box)\n",
    "        ih, iw, _ = image.shape\n",
    "        # Resize image\n",
    "        image = cv2.resize(image, (w, h))\n",
    "        # Flip image or not\n",
    "        flip = _rand() < .5\n",
    "        if flip:\n",
    "            image = cv2.flip(image, 1, dst=None)\n",
    "        # When the channels of image is 1\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            image = np.concatenate([image, image, image], axis=-1)\n",
    "        box[:, [0, 2]] = box[:, [0, 2]] / ih\n",
    "        box[:, [1, 3]] = box[:, [1, 3]] / iw\n",
    "        if flip:\n",
    "            box[:, [1, 3]] = 1 - box[:, [3, 1]]\n",
    "        box, label, num_match = ssd_bboxes_encode(box)\n",
    "        return image, box, label, num_match\n",
    "    return _data_aug(image, box, is_training, image_size=config.img_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18d684",
   "metadata": {},
   "source": [
    "### 2.2 数据集创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec706a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import mindspore.dataset as de\n",
    "\n",
    "def create_ssd_dataset(mindrecord_file, batch_size=32, device_num=1, rank=0,\n",
    "                       is_training=True, num_parallel_workers=4, use_multiprocessing=True):\n",
    "    \"\"\"Create SSD dataset with MindDataset.\"\"\"\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"img_id\", \"image\", \"annotation\"], num_shards=device_num,\n",
    "                        shard_id=rank, num_parallel_workers=num_parallel_workers, shuffle=is_training)\n",
    "    decode = de.vision.Decode()\n",
    "    ds = ds.map(operations=decode, input_columns=[\"image\"])\n",
    "    change_swap_op = de.vision.HWC2CHW()\n",
    "    # Computed from random subset of ImageNet training images\n",
    "    normalize_op = de.vision.Normalize(mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "                                       std=[0.229 * 255, 0.224 * 255, 0.225 * 255])\n",
    "    color_adjust_op = de.vision.RandomColorAdjust(brightness=0.4, contrast=0.4, saturation=0.4)\n",
    "    compose_map_func = (lambda img_id, image, annotation: preprocess_fn(img_id, image, annotation, is_training))\n",
    "    if is_training:\n",
    "        output_columns = [\"image\", \"box\", \"label\", \"num_match\"]\n",
    "        trans = [color_adjust_op, normalize_op, change_swap_op]\n",
    "    else:\n",
    "        output_columns = [\"img_id\", \"image\", \"image_shape\"]\n",
    "        trans = [normalize_op, change_swap_op]\n",
    "    ds = ds.map(operations=compose_map_func, input_columns=[\"img_id\", \"image\", \"annotation\"],\n",
    "                output_columns=output_columns, column_order=output_columns,\n",
    "                python_multiprocessing=use_multiprocessing,\n",
    "                num_parallel_workers=num_parallel_workers)\n",
    "    ds = ds.map(operations=trans, input_columns=[\"image\"], python_multiprocessing=use_multiprocessing,\n",
    "                num_parallel_workers=num_parallel_workers)\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f75e8f",
   "metadata": {},
   "source": [
    "## 4 模型构建\n",
    "本案例实现过程中采用VGG16作为特征提取阶段的backbone，并在之上进行了一些改善。首先VGG16是在ILSVRC CLS-LOC数据集预训练。 \n",
    "\n",
    "![图片](./src/img/441a293cb82c1ebecc4f67b0e03c2b05.png)  \n",
    "\n",
    "图2 基础的VGG结构 \n",
    "\n",
    "输入图像经过预处理后大小固定为300×300，首先经过backbone，本案例中使用的是VGG16网络的前13个卷积层，然后分别将VGG16的全连接层fc6和fc7转换成3$\\times$3卷积层block6和1$\\times$1卷积层block7，进一步提取特征。 在block6中，使用了空洞数为6的空洞卷积，其padding也为6，这样做同样也是为了增加感受野的同时保持参数量与特征图尺寸的不变。 利用mindspore构造该基础网络时，只需要在官方VGG16的基础上进行一些修改即可。  \n",
    "\n",
    "在此基础上，SSD进一步增加了4个深度卷积层：block8-11，用于更高语义信息的提取。block8的通道数为512，而block9、block10与block11的通道数都为256。为了降低参数量，在此使用了1×1卷积先降低通道数为该层输出通道数的一半，再利用3×3卷积进行特征提取。  \n",
    "  \n",
    "先验框与边框特征提取  \n",
    "SSD采用了PriorBox来进行区域生成。将固定大小宽高的PriorBox作为先验的感兴趣区域，利用一个阶段完成了分类与回归。PriorBox本质上是在原图上的一系列矩形框，如图所示。某个特征图上的一个点根据下采样率可以得到在原图的坐标，SSD先验性地提供了以该坐标为中心的4个或6个不同大小的PriorBox，然后利用特征图的特征去预测这4个PriorBox的类别与位置偏移量。  \n",
    "  \n",
    "SSD使用了第4、7、8、9、10和11这6个卷积层得到的特征图，这6个特征图尺寸越来越小，而其对应的感受野越来越大。6个特征图上的每一个点分别对应3、6、6、6、6、6个PriorBox。接下来分别利用3×3的卷积，即可得到每一个PriorBox对应的类别与位置预测量。 举个例子，第8个卷积层得到的特征图大小为10×10×512，每个点对应6个PriorBox，一共有600个PriorBox。由于采用的PASCAL VOC数据集的物体类别为21类，因此3×3卷积后得到的类别特征维度为6×21=126，位置特征维度为6×4（乘以4是因为有四个位置的框）=24。 如何确定每一个特征图PriorBox的具体大小呢？由于越深的特征图拥有的感受野越大，因此其对应的PriorBox也应越来越大，SSD采用了公式来计算每一个特征图对应的PriorBox的尺度。  \n",
    "定义MultiBox类（生成多个预测框）  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354a9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from src.vgg16 import vgg16\n",
    "import mindspore.ops as ops\n",
    "import ml_collections\n",
    "from src.config import get_config\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"ensures that all layers have a channel number that is divisible by 8.\"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def _conv2d(in_channel, out_channel, kernel_size=3, stride=1, pad_mod='same'):\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride,\n",
    "                     padding=0, pad_mode=pad_mod, has_bias=True)\n",
    "\n",
    "\n",
    "def _bn(channel):\n",
    "    return nn.BatchNorm2d(channel, eps=1e-3, momentum=0.97,\n",
    "                          gamma_init=1, beta_init=0, moving_mean_init=0, moving_var_init=1)\n",
    "\n",
    "\n",
    "def _last_conv2d(in_channel, out_channel, kernel_size=3, stride=1, pad_mod='same', pad=0):\n",
    "    in_channels = in_channel\n",
    "    out_channels = in_channel\n",
    "    depthwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad_mode='same',\n",
    "                               padding=pad, group=in_channels)\n",
    "    conv = _conv2d(in_channel, out_channel, kernel_size=1)\n",
    "    return nn.SequentialCell([depthwise_conv, _bn(in_channel), nn.ReLU6(), conv])\n",
    "\n",
    "\n",
    "class FlattenConcat(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super(FlattenConcat, self).__init__()\n",
    "        self.num_ssd_boxes = config.num_ssd_boxes\n",
    "        self.concat = ops.Concat(axis=1)\n",
    "        self.transpose = ops.Transpose()\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        output = ()\n",
    "        batch_size = ops.shape(inputs[0])[0]\n",
    "        for x in inputs:\n",
    "            x = self.transpose(x, (0, 2, 3, 1))\n",
    "            output += (ops.reshape(x, (batch_size, -1)),)\n",
    "        res = self.concat(output)\n",
    "        return ops.reshape(res, (batch_size, self.num_ssd_boxes, -1))\n",
    "\n",
    "\n",
    "class MultiBox(nn.Cell):\n",
    "    \"\"\"\n",
    "    Multibox conv layers. Each multibox layer contains class conf scores and localization predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(MultiBox, self).__init__()\n",
    "        num_classes = 81\n",
    "        out_channels = [512, 1024, 512, 256, 256, 256]\n",
    "        num_default = config.num_default\n",
    "\n",
    "        loc_layers = []\n",
    "        cls_layers = []\n",
    "        for k, out_channel in enumerate(out_channels):\n",
    "            loc_layers += [_last_conv2d(out_channel, 4 * num_default[k],\n",
    "                                        kernel_size=3, stride=1, pad_mod='same', pad=0)]\n",
    "            cls_layers += [_last_conv2d(out_channel, num_classes * num_default[k],\n",
    "                                        kernel_size=3, stride=1, pad_mod='same', pad=0)]\n",
    "\n",
    "        self.multi_loc_layers = nn.layer.CellList(loc_layers)\n",
    "        self.multi_cls_layers = nn.layer.CellList(cls_layers)\n",
    "        self.flatten_concat = FlattenConcat(config)\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        loc_outputs = ()\n",
    "        cls_outputs = ()\n",
    "        for i in range(len(self.multi_loc_layers)):\n",
    "            loc_outputs += (self.multi_loc_layers[i](inputs[i]),)\n",
    "            cls_outputs += (self.multi_cls_layers[i](inputs[i]),)\n",
    "        return self.flatten_concat(loc_outputs), self.flatten_concat(cls_outputs)\n",
    "\n",
    "\n",
    "class SSD300VGG16(nn.Cell):\n",
    "    def __init__(self, config):\n",
    "        super(SSD300VGG16, self).__init__()\n",
    "\n",
    "        # VGG16 backbone: block1~5\n",
    "        self.backbone = vgg16()\n",
    "\n",
    "        # SSD blocks: block6~7\n",
    "        self.b6_1 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=6, dilation=6, pad_mode='pad')\n",
    "        self.b6_2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.b7_1 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=1)\n",
    "        self.b7_2 = nn.Dropout(0.5)\n",
    "\n",
    "        # Extra Feature Layers: block8~11\n",
    "        self.b8_1 = nn.Conv2d(in_channels=1024, out_channels=256, kernel_size=1, padding=1, pad_mode='pad')\n",
    "        self.b8_2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, pad_mode='valid')\n",
    "\n",
    "        self.b9_1 = nn.Conv2d(in_channels=512, out_channels=128, kernel_size=1, padding=1, pad_mode='pad')\n",
    "        self.b9_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, pad_mode='valid')\n",
    "\n",
    "        self.b10_1 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1)\n",
    "        self.b10_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, pad_mode='valid')\n",
    "\n",
    "        self.b11_1 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1)\n",
    "        self.b11_2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, pad_mode='valid')\n",
    "\n",
    "        # boxes\n",
    "        self.multi_box = MultiBox(config)\n",
    "        if not self.training:\n",
    "            self.activation = ops.Sigmoid()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # VGG16 backbone: block1~5\n",
    "        block4, x = self.backbone(x)\n",
    "\n",
    "        # SSD blocks: block6~7\n",
    "        x = self.b6_1(x)  # 1024\n",
    "        x = self.b6_2(x)\n",
    "\n",
    "        x = self.b7_1(x)  # 1024\n",
    "        x = self.b7_2(x)\n",
    "        block7 = x\n",
    "\n",
    "        # Extra Feature Layers: block8~11\n",
    "        x = self.b8_1(x)  # 256\n",
    "        x = self.b8_2(x)  # 512\n",
    "        block8 = x\n",
    "\n",
    "        x = self.b9_1(x)  # 128\n",
    "        x = self.b9_2(x)  # 256\n",
    "        block9 = x\n",
    "\n",
    "        x = self.b10_1(x)  # 128\n",
    "        x = self.b10_2(x)  # 256\n",
    "        block10 = x\n",
    "\n",
    "        x = self.b11_1(x)  # 128\n",
    "        x = self.b11_2(x)  # 256\n",
    "        block11 = x\n",
    "\n",
    "        # boxes\n",
    "        multi_feature = (block4, block7, block8, block9, block10, block11)\n",
    "        pred_loc, pred_label = self.multi_box(multi_feature)\n",
    "        if not self.training:\n",
    "            pred_label = self.activation(pred_label)\n",
    "        pred_loc = ops.cast(pred_loc, ms.float32)\n",
    "        pred_label = ops.cast(pred_label, ms.float32)\n",
    "        return pred_loc, pred_label\n",
    "\n",
    "\n",
    "def ssd_vgg16(**kwargs):\n",
    "    return SSD300VGG16(**kwargs)\n",
    "\n",
    "\n",
    "# ssd = ssd_vgg16(config=config)\n",
    "# print(ssd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a19ba3",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "损失函数定义为位置误差（locatization loss， loc）与置信度误差（confidence loss, conf）的加权和：  \n",
    "其中  是先验框的正样本数量。这里  为一个指示参数，当  时表示第  个先验框与第  个ground truth匹配，并且ground truth的类别为  。  为类别置信度预测值。  为先验框的所对应边界框的位置预测值，而  是ground truth的位置参数。对于位置误差，其采用Smooth L1 loss，定义如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72446fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "\n",
    "grad_scale = ops.MultitypeFuncGraph(\"grad_scale\")\n",
    "\n",
    "\n",
    "class SigmoidFocalClassificationLoss(nn.Cell):\n",
    "    \"\"\"\"\n",
    "    Sigmoid focal-loss for classification.\n",
    "    Args:\n",
    "        gamma (float): Hyper-parameter to balance the easy and hard examples. Default: 2.0\n",
    "        alpha (float): Hyper-parameter to balance the positive and negative example. Default: 0.25\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(SigmoidFocalClassificationLoss, self).__init__()\n",
    "        self.sigmiod_cross_entropy = ops.SigmoidCrossEntropyWithLogits()\n",
    "        self.sigmoid = ops.Sigmoid()\n",
    "        self.pow = ops.Pow()\n",
    "        self.onehot = ops.OneHot()\n",
    "        self.on_value = Tensor(1.0, ms.float32)\n",
    "        self.off_value = Tensor(0.0, ms.float32)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def construct(self, logits, label):\n",
    "        label = self.onehot(label, ops.shape(logits)[-1], self.on_value, self.off_value)\n",
    "        sigmiod_cross_entropy = self.sigmiod_cross_entropy(logits, label)\n",
    "        sigmoid = self.sigmoid(logits)\n",
    "        label = ops.cast(label, ms.float32)\n",
    "        p_t = label * sigmoid + (1 - label) * (1 - sigmoid)\n",
    "        modulating_factor = self.pow(1 - p_t, self.gamma)\n",
    "        alpha_weight_factor = label * self.alpha + (1 - label) * (1 - self.alpha)\n",
    "        focal_loss = modulating_factor * alpha_weight_factor * sigmiod_cross_entropy\n",
    "        return focal_loss\n",
    "\n",
    "\n",
    "class SSDWithLossCell(nn.Cell):\n",
    "    \"\"\"\"\n",
    "    Provide SSD training loss through network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, network, config):\n",
    "        super(SSDWithLossCell, self).__init__()\n",
    "        self.network = network\n",
    "        self.less = ops.Less()\n",
    "        self.tile = ops.Tile()\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.expand_dims = ops.ExpandDims()\n",
    "        self.class_loss = SigmoidFocalClassificationLoss(config.gamma, config.alpha)\n",
    "        self.loc_loss = nn.SmoothL1Loss()\n",
    "\n",
    "    def construct(self, x, gt_loc, gt_label, num_matched_boxes):\n",
    "        pred_loc, pred_label = self.network(x)\n",
    "        mask = ops.cast(self.less(0, gt_label), ms.float32)\n",
    "        num_matched_boxes = self.reduce_sum(ops.cast(num_matched_boxes, ms.float32))\n",
    "        # 定位损失\n",
    "        mask_loc = self.tile(self.expand_dims(mask, -1), (1, 1, 4))\n",
    "        smooth_l1 = self.loc_loss(pred_loc, gt_loc) * mask_loc\n",
    "        loss_loc = self.reduce_sum(self.reduce_sum(smooth_l1, -1), -1)\n",
    "\n",
    "        # 类别损失\n",
    "        loss_cls = self.class_loss(pred_label, gt_label)\n",
    "        loss_cls = self.reduce_sum(loss_cls, (1, 2))\n",
    "\n",
    "        return self.reduce_sum((loss_cls + loss_loc) / num_matched_boxes)\n",
    "\n",
    "# net = SSDWithLossCell(ssd, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b2cc1",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590d1204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "from mindspore import save_checkpoint\n",
    "from mindspore.train.callback import Callback\n",
    "import json\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from src.config import get_config\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "\n",
    "def apply_eval(eval_param_dict):\n",
    "    net = eval_param_dict[\"net\"]\n",
    "    net.set_train(False)\n",
    "    ds = eval_param_dict[\"dataset\"]\n",
    "    anno_json = eval_param_dict[\"anno_json\"]\n",
    "    coco_metrics = COCOMetrics(anno_json=anno_json,\n",
    "                               classes=config.classes,\n",
    "                               num_classes=config.num_classes,\n",
    "                               max_boxes=config.max_boxes,\n",
    "                               nms_threshold=config.nms_threshold,\n",
    "                               min_score=config.min_score)\n",
    "    for data in ds.create_dict_iterator(output_numpy=True, num_epochs=1):\n",
    "        img_id = data['img_id']\n",
    "        img_np = data['image']\n",
    "        image_shape = data['image_shape']\n",
    "\n",
    "        output = net(Tensor(img_np))\n",
    "\n",
    "        for batch_idx in range(img_np.shape[0]):\n",
    "            pred_batch = {\n",
    "                \"boxes\": output[0].asnumpy()[batch_idx],\n",
    "                \"box_scores\": output[1].asnumpy()[batch_idx],\n",
    "                \"img_id\": int(np.squeeze(img_id[batch_idx])),\n",
    "                \"image_shape\": image_shape[batch_idx]\n",
    "            }\n",
    "            coco_metrics.update(pred_batch)\n",
    "    eval_metrics = coco_metrics.get_metrics()\n",
    "    return eval_metrics\n",
    "\n",
    "\n",
    "def apply_nms(all_boxes, all_scores, thres, max_boxes):\n",
    "    \"\"\"Apply NMS to bboxes.\"\"\"\n",
    "    y1 = all_boxes[:, 0]\n",
    "    x1 = all_boxes[:, 1]\n",
    "    y2 = all_boxes[:, 2]\n",
    "    x2 = all_boxes[:, 3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\n",
    "    order = all_scores.argsort()[::-1]\n",
    "    keep = []\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        if len(keep) >= max_boxes:\n",
    "            break\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thres)[0]\n",
    "\n",
    "        order = order[inds + 1]\n",
    "    return keep\n",
    "\n",
    "\n",
    "class COCOMetrics:\n",
    "    \"\"\"Calculate mAP of predicted bboxes.\"\"\"\n",
    "\n",
    "    def __init__(self, anno_json, classes, num_classes, min_score, nms_threshold, max_boxes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = classes\n",
    "        self.min_score = min_score\n",
    "        self.nms_threshold = nms_threshold\n",
    "        self.max_boxes = max_boxes\n",
    "\n",
    "        self.val_cls_dict = {i: cls for i, cls in enumerate(classes)}\n",
    "        self.coco_gt = COCO(anno_json)\n",
    "        cat_ids = self.coco_gt.loadCats(self.coco_gt.getCatIds())\n",
    "        self.class_dict = {cat['name']: cat['id'] for cat in cat_ids}\n",
    "\n",
    "        self.predictions = []\n",
    "        self.img_ids = []\n",
    "\n",
    "    def update(self, batch):\n",
    "        pred_boxes = batch['boxes']\n",
    "        box_scores = batch['box_scores']\n",
    "        img_id = batch['img_id']\n",
    "        h, w = batch['image_shape']\n",
    "\n",
    "        final_boxes = []\n",
    "        final_label = []\n",
    "        final_score = []\n",
    "        self.img_ids.append(img_id)\n",
    "\n",
    "        for c in range(1, self.num_classes):\n",
    "            class_box_scores = box_scores[:, c]\n",
    "            score_mask = class_box_scores > self.min_score\n",
    "            class_box_scores = class_box_scores[score_mask]\n",
    "            class_boxes = pred_boxes[score_mask] * [h, w, h, w]\n",
    "\n",
    "            if score_mask.any():\n",
    "                nms_index = apply_nms(class_boxes, class_box_scores, self.nms_threshold, self.max_boxes)\n",
    "                class_boxes = class_boxes[nms_index]\n",
    "                class_box_scores = class_box_scores[nms_index]\n",
    "\n",
    "                final_boxes += class_boxes.tolist()\n",
    "                final_score += class_box_scores.tolist()\n",
    "                final_label += [self.class_dict[self.val_cls_dict[c]]] * len(class_box_scores)\n",
    "\n",
    "        for loc, label, score in zip(final_boxes, final_label, final_score):\n",
    "            res = {}\n",
    "            res['image_id'] = img_id\n",
    "            res['bbox'] = [loc[1], loc[0], loc[3] - loc[1], loc[2] - loc[0]]\n",
    "            res['score'] = score\n",
    "            res['category_id'] = label\n",
    "            self.predictions.append(res)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        with open('predictions.json', 'w') as f:\n",
    "            json.dump(self.predictions, f)\n",
    "\n",
    "        coco_dt = self.coco_gt.loadRes('predictions.json')\n",
    "        E = COCOeval(self.coco_gt, coco_dt, iouType='bbox')\n",
    "        E.params.imgIds = self.img_ids\n",
    "        E.evaluate()\n",
    "        E.accumulate()\n",
    "        E.summarize()\n",
    "        return E.stats[0]\n",
    "\n",
    "\n",
    "class SsdInferWithDecoder(nn.Cell):\n",
    "    \"\"\"\n",
    "    SSD Infer wrapper to decode the bbox locations.\n",
    "    Args:\n",
    "        network (Cell): the origin ssd infer network without bbox decoder.\n",
    "        default_boxes (Tensor): the default_boxes from anchor generator\n",
    "        config (dict): ssd config\n",
    "    Returns:\n",
    "        Tensor, the locations for bbox after decoder representing (y0,x0,y1,x1)\n",
    "        Tensor, the prediction labels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, network, default_boxes, config):\n",
    "        super(SsdInferWithDecoder, self).__init__()\n",
    "        self.network = network\n",
    "        self.default_boxes = default_boxes\n",
    "        self.prior_scaling_xy = config.prior_scaling[0]\n",
    "        self.prior_scaling_wh = config.prior_scaling[1]\n",
    "\n",
    "    def construct(self, x):\n",
    "        pred_loc, pred_label = self.network(x)\n",
    "\n",
    "        default_bbox_xy = self.default_boxes[..., :2]\n",
    "        default_bbox_wh = self.default_boxes[..., 2:]\n",
    "        pred_xy = pred_loc[..., :2] * self.prior_scaling_xy * default_bbox_wh + default_bbox_xy\n",
    "        pred_wh = ops.Exp()(pred_loc[..., 2:] * self.prior_scaling_wh) * default_bbox_wh\n",
    "\n",
    "        pred_xy_0 = pred_xy - pred_wh / 2.0\n",
    "        pred_xy_1 = pred_xy + pred_wh / 2.0\n",
    "        pred_xy = ops.Concat(-1)((pred_xy_0, pred_xy_1))\n",
    "        pred_xy = ops.Maximum()(pred_xy, 0)\n",
    "        pred_xy = ops.Minimum()(pred_xy, 1)\n",
    "        return pred_xy, pred_label\n",
    "\n",
    "\n",
    "class EvalCallBack(Callback):\n",
    "    \"\"\"\n",
    "    Evaluation callback when training.\n",
    "\n",
    "    Args:\n",
    "        eval_function (function): evaluation function.\n",
    "        eval_param_dict (dict): evaluation parameters' configure dict.\n",
    "        interval (int): run evaluation interval, default is 1.\n",
    "        eval_start_epoch (int): evaluation start epoch, default is 1.\n",
    "        save_best_ckpt (bool): Whether to save best checkpoint, default is True.\n",
    "        besk_ckpt_name (str): bast checkpoint name, default is `best.ckpt`.\n",
    "        metrics_name (str): evaluation metrics name, default is `acc`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eval_function, eval_param_dict, interval=1, eval_start_epoch=1,\n",
    "                 ckpt_directory=\"./\", besk_ckpt_name=\"best.ckpt\", metrics_name=\"acc\"):\n",
    "        super(EvalCallBack, self).__init__()\n",
    "        self.eval_param_dict = eval_param_dict\n",
    "        self.eval_function = eval_function\n",
    "        self.eval_start_epoch = eval_start_epoch\n",
    "        self.interval = interval\n",
    "        self.best_res = 0\n",
    "        self.best_epoch = 0\n",
    "        if not os.path.isdir(ckpt_directory):\n",
    "            os.makedirs(ckpt_directory)\n",
    "        self.best_ckpt_path = os.path.join(ckpt_directory, besk_ckpt_name)\n",
    "        self.metrics_name = metrics_name\n",
    "\n",
    "\n",
    "    def epoch_end(self, run_context):\n",
    "        \"\"\"Callback when epoch end.\"\"\"\n",
    "        cb_params = run_context.original_args()\n",
    "        cur_epoch = cb_params.cur_epoch_num\n",
    "        if cur_epoch >= self.eval_start_epoch and (cur_epoch - self.eval_start_epoch) % self.interval == 0:\n",
    "            res = self.eval_function(self.eval_param_dict)\n",
    "            print(\"epoch: {}, {}: {}\".format(cur_epoch, self.metrics_name, res), flush=True)\n",
    "            if res >= self.best_res:\n",
    "                self.best_res = res\n",
    "                self.best_epoch = cur_epoch\n",
    "                print(\"update best result: {}\".format(res), flush=True)\n",
    "                save_checkpoint(cb_params.train_network, self.best_ckpt_path)\n",
    "                print(\"update best checkpoint at: {}\".format(self.best_ckpt_path), flush=True)\n",
    "\n",
    "    def end(self, run_context):\n",
    "        print(\"End training, the best {0} is: {1}, the best {0} epoch is {2}\".format(self.metrics_name,\n",
    "                                                                                     self.best_res,\n",
    "                                                                                     self.best_epoch), flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e45a95",
   "metadata": {},
   "source": [
    "### 训练过程\n",
    "a）先验框匹配  \n",
    "在训练过程中，首先要确定训练图片中的ground truth（真实目标）与哪个先验框来进行匹配，与之匹配的先验框所对应的边界框将负责预测它。在Yolo中，ground truth的中心落在哪个单元格，该单元格中与其IOU最大的边界框负责预测它。但是在SSD中却完全不一样，SSD的先验框与ground truth的匹配原则主要有两点。首先，对于图片中每个ground truth，找到与其IOU最大的先验框，该先验框与其匹配，这样，可以保证每个ground truth一定与某个先验框匹配。通常称与ground truth匹配的先验框为正样本（其实应该是先验框对应的预测box，不过由于是一一对应的就这样称呼了），反之，若一个先验框没有与任何ground truth进行匹配，那么该先验框只能与背景匹配，就是负样本。一个图片中ground truth是非常少的， 而先验框却很多，如果仅按第一个原则匹配，很多先验框会是负样本，正负样本极其不平衡，所以需要第二个原则。第二个原则是：对于剩余的未匹配先验框，若某个ground truth的  大于某个阈值（一般是0.5），那么该先验框也与这个ground truth进行匹配。这意味着某个ground truth可能与多个先验框匹配，这是可以的。但是反过来却不可以，因为一个先验框只能匹配一个ground truth，如果多个ground truth与某个先验框  大于阈值，那么先验框只与IOU最大的那个ground truth进行匹配。第二个原则一定在第一个原则之后进行，仔细考虑一下这种情况，如果某个ground truth所对应最大  小于阈值，并且所匹配的先验框却与另外一个ground truth的  大于阈值，那么该先验框应该匹配谁，答案应该是前者，首先要确保某个ground truth一定有一个先验框与之匹配。但是，这种情况我觉得基本上是不存在的。由于先验框很多，某个ground truth的最大  肯定大于阈值，所以可能只实施第二个原则既可以了，这里的TensorFlow版本就是只实施了第二个原则，但是这里的Pytorch两个原则都实施了。图8为一个匹配示意图，其中绿色的GT是ground truth，红色为先验框，FP表示负样本，TP表示正样本。  \n",
    "尽管一个ground truth可以与多个先验框匹配，但是ground truth相对先验框还是太少了，所以负样本相对正样本会很多。为了保证正负样本尽量平衡，SSD采用了hard negative mining，就是对负样本进行抽样，抽样时按照置信度误差（预测背景的置信度越小，误差越大）进行降序排列，选取误差的较大的top-k作为训练的负样本，以保证正负样本比例接近1:3。\n",
    "### 预测过程  \n",
    "预测过程比较简单，对于每个预测框，首先根据类别置信度确定其类别（置信度最大者）与置信度值，并过滤掉属于背景的预测框。然后根据置信度阈值（如0.5）过滤掉阈值较低的预测框。对于留下的预测框进行解码，根据先验框得到其真实的位置参数（解码后一般还需要做clip，防止预测框位置超出图片）。解码之后，一般需要根据置信度进行降序排列，然后仅保留top-k（如400）个预测框。最后就是进行NMS算法，过滤掉那些重叠度较大的预测框。最后剩余的预测框就是检测结果了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c5f05d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(25356:140328575960896,MainProcess):2022-09-27-20:11:55.770.206 [mindspore/train/model.py:1077] For EvalCallBack callback, {'end', 'epoch_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:01.796.947 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 86.5851%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:02.083.333 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 87.0034%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:02.379.465 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 87.1241%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:02.634.794 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 87.5132%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:02.852.626 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 87.8775%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:03.230.968 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 88.2709%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:03.672.022 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 88.7457%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n",
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:07.005.838 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 90.3376%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 9, loss is 134.17556762695312\n",
      "Train epoch time: 12829.201 ms, per step time: 1425.467 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:08.613.030 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 90.3535%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 9, loss is 34.621246337890625\n",
      "Train epoch time: 1536.725 ms, per step time: 170.747 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:10.154.185 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 90.4047%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 9, loss is 55.49814224243164\n",
      "Train epoch time: 1530.724 ms, per step time: 170.080 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:11.826.512 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:11.826.532 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:11.866.062 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:11.866.084 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:11.921.364 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:11.921.388 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:12.089.494 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 90.5255%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.27s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      "epoch: 3, mAP: 0.014478793309438472\n",
      "update best result: 0.014478793309438472\n",
      "update best checkpoint at: ./cache/train/ckpt_0/best_map.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:16.404.028 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 91.69%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 9, loss is 175.6864013671875\n",
      "Train epoch time: 1527.530 ms, per step time: 169.726 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:17.938.638 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 91.7765%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 9, loss is 185.91725158691406\n",
      "Train epoch time: 1584.904 ms, per step time: 176.100 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:19.546.836 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:19.546.866 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:19.578.483 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:19.578.505 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:19.812.274 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 91.8861%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.42s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.175\n",
      "epoch: 5, mAP: 0.014315998850220238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:21.240.851 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.0877%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 step: 9, loss is 17.611614227294922\n",
      "Train epoch time: 1553.843 ms, per step time: 172.649 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:22.792.231 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.1118%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 step: 9, loss is 12.627750396728516\n",
      "Train epoch time: 1545.307 ms, per step time: 171.701 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:24.374.076 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:24.374.097 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:24.392.164 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:24.392.186 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:24.569.528 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.1435%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.32s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.25s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "epoch: 7, mAP: 0.011754933075829343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:34.889.378 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.1782%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 step: 9, loss is 13.021714210510254\n",
      "Train epoch time: 1424.357 ms, per step time: 158.262 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:36.318.325 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.1763%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 step: 9, loss is 14.391738891601562\n",
      "Train epoch time: 1435.383 ms, per step time: 159.487 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:37.763.048 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:37.763.065 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:37.793.335 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:37.793.355 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:37.957.456 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.2004%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.19s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
      "epoch: 9, mAP: 0.0008311086817397974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:38.920.958 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.2219%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 step: 9, loss is 9.936471939086914\n",
      "Train epoch time: 3100.084 ms, per step time: 344.454 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:42.033.482 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.3208%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 step: 9, loss is 8.581490516662598\n",
      "Train epoch time: 1429.329 ms, per step time: 158.814 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:43.478.304 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:43.478.319 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:43.493.348 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:43.493.373 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:43.617.562 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.289%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.15s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.167\n",
      "epoch: 11, mAP: 0.0005079791962005061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:44.475.986 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.4637%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 step: 9, loss is 7.886897563934326\n",
      "Train epoch time: 1511.100 ms, per step time: 167.900 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:45.995.148 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.4632%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 step: 9, loss is 7.835870742797852\n",
      "Train epoch time: 1447.716 ms, per step time: 160.857 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:47.466.244 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:47.466.261 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:47.477.542 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:47.477.567 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:47.589.695 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.4517%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      "epoch: 13, mAP: 0.004839240242763193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:48.826.218 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.475%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 step: 9, loss is 9.964936256408691\n",
      "Train epoch time: 1467.678 ms, per step time: 163.075 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:50.292.962 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.4844%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 step: 9, loss is 11.922388076782227\n",
      "Train epoch time: 1457.475 ms, per step time: 161.942 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:51.770.042 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:51.770.059 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:51.789.349 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:51.789.370 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:51.905.476 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.5295%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.078\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.233\n",
      "epoch: 15, mAP: 0.0034404079226615304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:52.944.542 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.535%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 step: 9, loss is 9.575481414794922\n",
      "Train epoch time: 1440.649 ms, per step time: 160.072 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:54.389.449 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.5815%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 step: 9, loss is 8.44621467590332\n",
      "Train epoch time: 1486.830 ms, per step time: 165.203 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:55.894.142 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:12:55.894.162 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:55.929.661 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:12:55.929.686 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:12:56.081.471 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.6735%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      "epoch: 17, mAP: 0.001279607267340228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:57.458.342 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.7593%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 step: 9, loss is 7.651590347290039\n",
      "Train epoch time: 1577.980 ms, per step time: 175.331 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:12:59.045.153 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.755%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 step: 9, loss is 7.581185340881348\n",
      "Train epoch time: 1804.047 ms, per step time: 200.450 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:00.870.123 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:00.870.144 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:00.897.343 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:00.897.364 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:01.031.701 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8036%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.049\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
      "epoch: 19, mAP: 0.0011493681036683623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:03.595.725 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.741%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 9, loss is 7.838171005249023\n",
      "Train epoch time: 3053.797 ms, per step time: 339.311 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:06.661.593 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.5234%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 step: 9, loss is 6.265202522277832\n",
      "Train epoch time: 1512.811 ms, per step time: 168.090 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:08.182.337 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:08.182.358 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:08.205.341 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:08.205.413 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:08.345.466 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.611%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.27s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      "epoch: 21, mAP: 0.0010596334631242641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:10.088.405 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.7379%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 step: 9, loss is 7.011441707611084\n",
      "Train epoch time: 1542.159 ms, per step time: 171.351 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:11.627.942 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.7852%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 step: 9, loss is 5.766232490539551\n",
      "Train epoch time: 1471.033 ms, per step time: 163.448 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:13.116.037 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:13.116.064 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:13.137.343 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:13.137.365 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:13.227.169 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8232%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "epoch: 23, mAP: 0.0035995984891952545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:14.924.855 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8313%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 step: 9, loss is 6.9969587326049805\n",
      "Train epoch time: 1468.591 ms, per step time: 163.177 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:16.396.442 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8616%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 step: 9, loss is 7.672084808349609\n",
      "Train epoch time: 1449.452 ms, per step time: 161.050 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:17.864.740 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:17.864.760 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:17.883.847 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:17.883.867 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:18.029.474 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8466%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.022\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083\n",
      "epoch: 25, mAP: 0.0009369109463938529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:19.585.316 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8045%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 step: 9, loss is 7.03197717666626\n",
      "Train epoch time: 1667.436 ms, per step time: 185.271 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:21.253.217 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9218%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 step: 9, loss is 6.549558639526367\n",
      "Train epoch time: 1465.729 ms, per step time: 162.859 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:22.734.590 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:22.734.610 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:22.765.441 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:22.765.512 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:22.925.503 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8779%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.40s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.079\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n",
      "epoch: 27, mAP: 0.004300654943131177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:24.753.654 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9352%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 step: 9, loss is 5.950974464416504\n",
      "Train epoch time: 1453.384 ms, per step time: 161.487 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:26.206.773 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9107%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 step: 9, loss is 6.467238426208496\n",
      "Train epoch time: 1459.734 ms, per step time: 162.193 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:27.682.351 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:27.682.376 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:27.717.363 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:27.717.381 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:27.865.475 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8671%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.28s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n",
      "epoch: 29, mAP: 0.009933266927094007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:29.694.756 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9242%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 step: 9, loss is 5.690110206604004\n",
      "Train epoch time: 2999.560 ms, per step time: 333.284 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:32.682.831 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.7951%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 step: 9, loss is 5.890345096588135\n",
      "Train epoch time: 1461.963 ms, per step time: 162.440 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:34.162.415 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:34.162.436 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:34.189.362 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:34.189.381 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:34.321.454 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.7391%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.33s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      "epoch: 31, mAP: 0.00834443485007527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:36.415.335 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9655%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 step: 9, loss is 6.137136936187744\n",
      "Train epoch time: 1542.276 ms, per step time: 171.364 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:37.960.178 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0797%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 step: 9, loss is 5.908548355102539\n",
      "Train epoch time: 1741.805 ms, per step time: 193.534 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:39.734.284 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:39.734.303 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:39.756.723 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:39.756.758 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:39.913.474 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0251%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.13s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      "epoch: 33, mAP: 0.003541788763767835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:41.849.491 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9977%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 step: 9, loss is 7.093789577484131\n",
      "Train epoch time: 1732.409 ms, per step time: 192.490 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:43.583.450 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0899%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 step: 9, loss is 5.367991924285889\n",
      "Train epoch time: 1694.687 ms, per step time: 188.299 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:45.309.845 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:45.309.871 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:45.337.400 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:45.337.435 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:45.497.510 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.1681%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.39s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      "epoch: 35, mAP: 0.006180690983739632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:47.593.933 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0152%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 step: 9, loss is 5.475518226623535\n",
      "Train epoch time: 1483.446 ms, per step time: 164.827 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:49.075.320 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9691%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 step: 9, loss is 5.278355121612549\n",
      "Train epoch time: 1470.871 ms, per step time: 163.430 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:50.578.257 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:50.578.282 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:50.621.335 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:50.621.354 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:50.759.497 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0405%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.078\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "epoch: 37, mAP: 0.03961041304562623\n",
      "update best result: 0.03961041304562623\n",
      "update best checkpoint at: ./cache/train/ckpt_0/best_map.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:54.231.174 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8405%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 step: 9, loss is 5.341988563537598\n",
      "Train epoch time: 1484.766 ms, per step time: 164.974 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:55.716.403 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8271%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 step: 9, loss is 5.879888534545898\n",
      "Train epoch time: 1442.775 ms, per step time: 160.308 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:57.182.002 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:13:57.182.025 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:57.197.337 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:13:57.197.358 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:13:57.318.357 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.8144%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.24s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.070\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      "epoch: 39, mAP: 0.00840752683261176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:13:59.228.261 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0691%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 step: 9, loss is 5.998709201812744\n",
      "Train epoch time: 3423.168 ms, per step time: 380.352 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:02.646.715 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9341%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41 step: 9, loss is 5.922650337219238\n",
      "Train epoch time: 1705.561 ms, per step time: 189.507 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:04.395.114 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:04.395.137 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:04.413.348 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:04.413.370 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:04.506.376 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9706%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.34s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.258\n",
      "epoch: 41, mAP: 0.01043863846313264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:06.614.294 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9949%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 step: 9, loss is 5.921730041503906\n",
      "Train epoch time: 1535.713 ms, per step time: 170.635 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:08.149.496 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0787%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 step: 9, loss is 5.049553394317627\n",
      "Train epoch time: 1449.764 ms, per step time: 161.085 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:09.625.978 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:09.625.996 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:09.653.342 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:09.653.361 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:09.800.840 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.9991%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.20s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.225\n",
      "epoch: 43, mAP: 0.011200616437023869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:11.606.795 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0412%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44 step: 9, loss is 6.531441688537598\n",
      "Train epoch time: 1501.449 ms, per step time: 166.828 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:13.099.156 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.071%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 step: 9, loss is 5.104480743408203\n",
      "Train epoch time: 1486.279 ms, per step time: 165.142 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:14.609.939 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:14.609.957 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:14.632.209 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:14.632.277 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:14.781.150 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0722%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.24s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.16s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.030\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.029\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.192\n",
      "epoch: 45, mAP: 0.010096524634136917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:16.489.440 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0689%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 step: 9, loss is 5.02818489074707\n",
      "Train epoch time: 1450.166 ms, per step time: 161.130 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:17.923.837 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.095%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 step: 9, loss is 6.079272270202637\n",
      "Train epoch time: 1496.997 ms, per step time: 166.333 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:19.440.191 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:19.440.213 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:19.463.142 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:19.463.163 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:19.549.477 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.1355%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.058\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      "epoch: 47, mAP: 0.022947671048214567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:21.518.815 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.2009%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 step: 9, loss is 5.376936912536621\n",
      "Train epoch time: 1514.119 ms, per step time: 168.235 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:23.036.873 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.2496%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 step: 9, loss is 5.524967670440674\n",
      "Train epoch time: 1485.310 ms, per step time: 165.034 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:24.542.041 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:24.542.059 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:24.557.344 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:24.557.366 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:24.693.421 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.1539%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.23s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
      "epoch: 49, mAP: 0.0024919246266033946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:26.747.630 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.2045%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50 step: 9, loss is 5.252786159515381\n",
      "Train epoch time: 3496.652 ms, per step time: 388.517 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:30.246.949 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0627%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 51 step: 9, loss is 4.823017120361328\n",
      "Train epoch time: 1658.339 ms, per step time: 184.260 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:31.934.300 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:31.934.321 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:31.961.354 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:31.961.374 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:32.093.382 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.0554%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.31s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.125\n",
      "epoch: 51, mAP: 0.006176747419889674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:34.140.390 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.1264%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52 step: 9, loss is 5.289878845214844\n",
      "Train epoch time: 1514.488 ms, per step time: 168.276 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7f9ed3fff700,python):2022-09-27-20:14:35.661.952 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 93.1999%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 53 step: 9, loss is 6.132433891296387\n",
      "Train epoch time: 1516.850 ms, per step time: 168.539 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:37.193.956 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:37.193.971 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:37.245.345 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:37.245.365 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:37.373.632 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.4446%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.41s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.056\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      "epoch: 53, mAP: 0.039478021003092854\n",
      "epoch: 54 step: 9, loss is 5.124389171600342\n",
      "Train epoch time: 1439.561 ms, per step time: 159.951 ms\n",
      "epoch: 55 step: 9, loss is 4.97568416595459\n",
      "Train epoch time: 1628.930 ms, per step time: 180.992 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:42.585.344 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:42.585.374 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:42.605.340 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:42.605.420 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:42.767.945 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.5718%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.44s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.025\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      "epoch: 55, mAP: 0.01034944186285487\n",
      "epoch: 56 step: 9, loss is 5.50404167175293\n",
      "Train epoch time: 1448.342 ms, per step time: 160.927 ms\n",
      "epoch: 57 step: 9, loss is 5.11041784286499\n",
      "Train epoch time: 1460.792 ms, per step time: 162.310 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:47.842.365 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:47.842.384 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:47.865.436 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:47.865.456 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:47.992.242 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.5131%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.22s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
      "epoch: 57, mAP: 0.010360043988884212\n",
      "epoch: 58 step: 9, loss is 5.663305282592773\n",
      "Train epoch time: 1453.934 ms, per step time: 161.548 ms\n",
      "epoch: 59 step: 9, loss is 4.86760139465332\n",
      "Train epoch time: 1461.233 ms, per step time: 162.359 ms\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:52.853.954 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7fa0caec0740,python):2022-09-27-20:14:52.853.976 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:52.877.335 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord1 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9db6ffd700,python):2022-09-27-20:14:52.877.353 [mindspore/ccsrc/minddata/mindrecord/io/shard_reader.cc:360] ReadRowGroupSummary] The mindrecord file: /media/su/sdisk/mindspore/ssd_ms/mini_dataset/MindRecord_COCO/ssd_eval.mindrecord3 does not contain any samples, pls remove it.\n",
      "[WARNING] MD(25356,7f9daa7e4700,python):2022-09-27-20:14:52.997.525 [mindspore/ccsrc/minddata/dataset/engine/datasetops/batch_op.cc:136] operator()] Memory consumption is more than 92.2685%, which may cause oom error. Please reduce num_parallel_workers size / optimize 'per_batch_map' function / other python data preprocess function to reduce memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.25s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.208\n",
      "epoch: 59, mAP: 0.01033629180771069\n",
      "epoch: 60 step: 9, loss is 5.360236167907715\n",
      "Train epoch time: 2937.841 ms, per step time: 326.427 ms\n",
      "End training, the best mAP is: 0.03961041304562623, the best mAP epoch is 37\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mindspore.train import Model\n",
    "from src.config import get_config\n",
    "import mindspore as ms\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, LossMonitor, TimeMonitor\n",
    "from src.init_params import init_net_param\n",
    "from src.lr_schedule import get_lr\n",
    "from mindspore.common import set_seed\n",
    "from src.box_utils import default_boxes\n",
    "\n",
    "\n",
    "class TrainingWrapper(nn.Cell):\n",
    "    \"\"\"\n",
    "    Encapsulation class of SSD network training.\n",
    "\n",
    "    Append an optimizer to the training network after that the construct\n",
    "    function can be called to create the backward graph.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): The training network. Note that loss function should have been added.\n",
    "        optimizer (Optimizer): Optimizer for updating the weights.\n",
    "        sens (Number): The adjust parameter. Default: 1.0.\n",
    "        use_global_nrom(bool): Whether apply global norm before optimizer. Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, network, optimizer, sens=1.0):\n",
    "        super(TrainingWrapper, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.network.set_grad()\n",
    "        self.weights = ms.ParameterTuple(network.trainable_params())\n",
    "        self.optimizer = optimizer\n",
    "        self.grad = ops.GradOperation(get_by_list=True, sens_param=True)\n",
    "        self.sens = sens\n",
    "        self.hyper_map = ops.HyperMap()\n",
    "\n",
    "    def construct(self, *args):\n",
    "        weights = self.weights\n",
    "        loss = self.network(*args)\n",
    "        sens = ops.Fill()(ops.DType()(loss), ops.Shape()(loss), self.sens)\n",
    "        grads = self.grad(self.network, weights)(*args, sens)\n",
    "        self.optimizer(grads)\n",
    "        return loss\n",
    "\n",
    "\n",
    "set_seed(1)\n",
    "# 自定义参数获取\n",
    "config = get_config()\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target= \"GPU\")\n",
    "\n",
    "# 数据加载\n",
    "mindrecord_dir = os.path.join(config.data_path, config.mindrecord_dir)\n",
    "mindrecord_file = os.path.join(mindrecord_dir, \"ssd.mindrecord\"+ \"0\")\n",
    "\n",
    "dataset = create_ssd_dataset(mindrecord_file, batch_size=config.batch_size,rank=0, use_multiprocessing=True)\n",
    "\n",
    "dataset_size = dataset.get_dataset_size()\n",
    "\n",
    "# checkpoint\n",
    "ckpt_config = CheckpointConfig(save_checkpoint_steps=dataset_size * config.save_checkpoint_epochs)\n",
    "ckpt_save_dir = config.output_path + '/ckpt_{}/'.format(0)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"ssd\", directory=ckpt_save_dir, config=ckpt_config)\n",
    "\n",
    "# 网络定义与初始化\n",
    "ssd = ssd_vgg16(config=config)\n",
    "init_net_param(ssd)\n",
    "# print(ssd)\n",
    "net = SSDWithLossCell(ssd, config)\n",
    "# print(net)\n",
    "lr = Tensor(get_lr(global_step=config.pre_trained_epoch_size * dataset_size,\n",
    "                   lr_init=config.lr_init, lr_end=config.lr_end_rate * config.lr, lr_max=config.lr,\n",
    "                   warmup_epochs=config.warmup_epochs,total_epochs=config.epoch_size,steps_per_epoch=dataset_size))\n",
    "opt = nn.Momentum(filter(lambda x: x.requires_grad, net.get_parameters()), lr,\n",
    "                  config.momentum, config.weight_decay,float(config.loss_scale))\n",
    "net = TrainingWrapper(net, opt, float(config.loss_scale))\n",
    "\n",
    "callback = [TimeMonitor(data_size=dataset_size), LossMonitor(), ckpoint_cb]\n",
    "\n",
    "# 评估\n",
    "eval_net = SsdInferWithDecoder(ssd, Tensor(default_boxes), config)\n",
    "eval_net.set_train(False)\n",
    "eval_mindrecord_dir = os.path.join(config.data_path, config.mindrecord_dir)\n",
    "eval_mindrecord_file = os.path.join(eval_mindrecord_dir, \"ssd_eval.mindrecord\" + \"0\")\n",
    "eval_dataset = create_ssd_dataset(eval_mindrecord_file, batch_size=config.batch_size,\n",
    "                                  is_training=False, use_multiprocessing=False)\n",
    "\n",
    "anno_json = os.path.join(config.coco_root, config.instances_set.format(config.val_data_type))\n",
    "eval_param_dict = {\"net\": eval_net, \"dataset\": eval_dataset, \"anno_json\": anno_json}\n",
    "eval_cb = EvalCallBack(apply_eval, eval_param_dict, interval=config.eval_interval,\n",
    "                       eval_start_epoch=config.eval_start_epoch,\n",
    "                       ckpt_directory=ckpt_save_dir, besk_ckpt_name=\"best_map.ckpt\",\n",
    "                       metrics_name=\"mAP\")\n",
    "callback.append(eval_cb)\n",
    "\n",
    "model = Model(net)\n",
    "model.train(config.epoch_size, dataset, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348509c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
